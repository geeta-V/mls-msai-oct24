{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# **Project 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Business Use Case**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Problem Statement:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the fast-paced environment of healthcare centers, healthcare professionals often face the challenge of quick and accurate diagnosis of patients while managing an ever-increasing volume of medical information. Ensuring that healthcare providers have access to the latest and most comprehensive medical knowledge is crucial for improving patient outcomes and reducing the time needed to make informed decisions.\n",
        "\n",
        "There are multiple challenges that these professionals encounter daily, a few being\n",
        "\n",
        "- Information Overload: Medical professionals need to go through vast amounts of data and research to make accurate diagnoses and treatment plans. This can be overwhelming and time-consuming.\n",
        "- Efficiency: For overall patient care and quality health outcomes, quick and accurate diagnosis is vital, especially in emergency situations.\n",
        "- Access to Trusted Knowledge: In the ever-evolving healthcare industry, providing access to reliable and up-to-date medical information from renowned manuals and research papers is essential for maintaining high standards of care.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Objective:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A renowned chain of hospitals has decided to leverage AI to build a state-of-the-art solution to help healthcare professionals overcome the aforementioned challenges. They have recruited you as an AI specialist and tasked you with building a RAG-based AI solution that leverages renowned medical manuals as its knowledge base. This AI system will act as a POC towards an end product that’ll assist healthcare professionals in making better, quicker, and more accurate diagnoses, ultimately leading to faster patient resolutions and enabling better patient outcomes by reducing errors in diagnosis, saving valuable time for information retrieval, and standardizing care practices across the board."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Questions:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**1. Diagnostic Assistance**: \"What are the common symptoms and treatments for pulmonary embolism?\"\n",
        "\n",
        "**2. Drug Information**: \"Can you provide the trade names of medications used for treating hypertension?\"\n",
        "\n",
        "**3. Treatment Plans**: \"What are the first-line options and alternatives for managing rheumatoid arthritis?\"\n",
        "\n",
        "**4. Specialty Knowledge**: \"What are the diagnostic steps for suspected endocrine disorders?\"\n",
        "\n",
        "**5. Critical Care Protocols**: \"What is the protocol for managing sepsis in a critical care unit?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **How This Application Empowers Professionals and Elevates Healthcare Organizations**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Enhanced Diagnostic Accuracy:**\n",
        "Provides evidence-based insights for better diagnosis and treatment.\n",
        "\n",
        "- **Time Efficiency:**\n",
        "Instantly retrieves critical information, saving valuable time.\n",
        "\n",
        "- **Improved Patient Care:**\n",
        "Ensures informed decisions with up-to-date medical knowledge.\n",
        "\n",
        "- **Cost-Effective Operations:**\n",
        "Reduces redundant tests and consultation delays, lowering costs.\n",
        "\n",
        "- **Knowledge Empowerment:**\n",
        "Keeps doctors updated on the latest advancements.\n",
        "\n",
        "- **Competitive Edge for the Hospital:**\n",
        "Positions the hospital as a leader in healthcare innovation.\n",
        "\n",
        "This collaboration between St. Bernard’s Medical Center and InnoviTech Solutions highlights the transformative potential of AI in revolutionizing healthcare."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **1. Install and Import Required Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1740798674169
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: azure-ai-ml in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (1.20.0)\n",
            "Requirement already satisfied: pyyaml>=5.1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (6.0.2)\n",
            "Requirement already satisfied: msrest>=0.6.18 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (0.7.1)\n",
            "Requirement already satisfied: azure-core>=1.23.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (1.31.0)\n",
            "Requirement already satisfied: azure-mgmt-core>=1.3.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (1.4.0)\n",
            "Requirement already satisfied: marshmallow>=3.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (3.22.0)\n",
            "Requirement already satisfied: jsonschema>=4.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (4.23.0)\n",
            "Requirement already satisfied: tqdm in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (4.66.5)\n",
            "Requirement already satisfied: strictyaml in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (1.7.3)\n",
            "Requirement already satisfied: colorama in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (0.4.6)\n",
            "Requirement already satisfied: pyjwt in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (2.9.0)\n",
            "Requirement already satisfied: azure-storage-blob>=12.10.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (12.23.0)\n",
            "Requirement already satisfied: azure-storage-file-share in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (12.18.0)\n",
            "Requirement already satisfied: azure-storage-file-datalake>=12.2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (12.17.0)\n",
            "Requirement already satisfied: pydash>=6.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (8.0.3)\n",
            "Requirement already satisfied: isodate in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (0.6.1)\n",
            "Requirement already satisfied: azure-common>=1.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (1.1.28)\n",
            "Requirement already satisfied: typing-extensions in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (4.12.2)\n",
            "Requirement already satisfied: opencensus-ext-azure in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (1.1.13)\n",
            "Requirement already satisfied: opencensus-ext-logging in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (0.1.1)\n",
            "Requirement already satisfied: requests>=2.21.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-core>=1.23.0->azure-ai-ml) (2.32.3)\n",
            "Requirement already satisfied: six>=1.11.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-core>=1.23.0->azure-ai-ml) (1.16.0)\n",
            "Requirement already satisfied: cryptography>=2.1.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-storage-blob>=12.10.0->azure-ai-ml) (43.0.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (0.20.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from marshmallow>=3.5->azure-ai-ml) (24.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from msrest>=0.6.18->azure-ai-ml) (2024.8.30)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from msrest>=0.6.18->azure-ai-ml) (2.0.0)\n",
            "Requirement already satisfied: azure-identity<2.0.0,>=1.5.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from opencensus-ext-azure->azure-ai-ml) (1.18.0)\n",
            "Requirement already satisfied: opencensus<1.0.0,>=0.11.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from opencensus-ext-azure->azure-ai-ml) (0.11.4)\n",
            "Requirement already satisfied: psutil>=5.6.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from opencensus-ext-azure->azure-ai-ml) (6.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from strictyaml->azure-ai-ml) (2.9.0)\n",
            "Requirement already satisfied: msal>=1.30.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure->azure-ai-ml) (1.31.0)\n",
            "Requirement already satisfied: msal-extensions>=1.2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure->azure-ai-ml) (1.2.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from cryptography>=2.1.4->azure-storage-blob>=12.10.0->azure-ai-ml) (1.17.1)\n",
            "Requirement already satisfied: opencensus-context>=0.1.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (0.1.3)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (2.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (2.2.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.18->azure-ai-ml) (3.2.2)\n",
            "Requirement already satisfied: pycparser in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob>=12.10.0->azure-ai-ml) (2.22)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (1.65.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (5.28.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (1.24.0)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (2.35.0)\n",
            "Requirement already satisfied: portalocker<3,>=1.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from msal-extensions>=1.2.0->azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure->azure-ai-ml) (2.10.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (0.6.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting azureml-rag>=0.2.36 (from azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading azureml_rag-0.2.38-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: azureml-dataprep>=5.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-dataprep[parquet]>=5.1->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (5.1.6)\n",
            "Requirement already satisfied: azureml-fsspec in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.3.1)\n",
            "Requirement already satisfied: fsspec~=2023.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (2023.10.0)\n",
            "Collecting openai>=0.27.8 (from azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading openai-1.65.1-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting tiktoken<1.0,>=0.7 (from azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: cloudpickle in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (2.2.1)\n",
            "Collecting mmh3 (from azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading mmh3-5.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (6.0.2)\n",
            "Requirement already satisfied: requests in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (2.32.3)\n",
            "Requirement already satisfied: azureml-core in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.57.0.post1)\n",
            "Collecting faiss-cpu~=1.7.3 (from azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: scikit-learn in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-rag[faiss,hugging_face]>=0.2.36) (1.5.2)\n",
            "Collecting sentence-transformers (from azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting huggingface-hub>=0.25.1 (from azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading huggingface_hub-0.29.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: azureml-dataprep-native<42.0.0,>=41.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-dataprep>=5.1->azureml-dataprep[parquet]>=5.1->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (41.0.0)\n",
            "Requirement already satisfied: azureml-dataprep-rslex~=2.22.2dev0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-dataprep>=5.1->azureml-dataprep[parquet]>=5.1->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (2.22.4)\n",
            "Requirement already satisfied: azure-identity>=1.7.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-dataprep>=5.1->azureml-dataprep[parquet]>=5.1->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.18.0)\n",
            "Requirement already satisfied: jsonschema in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-dataprep>=5.1->azureml-dataprep[parquet]>=5.1->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (4.23.0)\n",
            "Requirement already satisfied: pyarrow>=0.17.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-dataprep[parquet]>=5.1->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (17.0.0)\n",
            "Requirement already satisfied: filelock in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from huggingface-hub>=0.25.1->azureml-rag[faiss,hugging_face]>=0.2.36) (3.16.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from huggingface-hub>=0.25.1->azureml-rag[faiss,hugging_face]>=0.2.36) (24.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from huggingface-hub>=0.25.1->azureml-rag[faiss,hugging_face]>=0.2.36) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from huggingface-hub>=0.25.1->azureml-rag[faiss,hugging_face]>=0.2.36) (4.12.2)\n",
            "Collecting anyio<5,>=3.5.0 (from openai>=0.27.8->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting distro<2,>=1.7.0 (from openai>=0.27.8->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting httpx<1,>=0.23.0 (from openai>=0.27.8->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai>=0.27.8->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading jiter-0.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting pydantic<3,>=1.9.0 (from openai>=0.27.8->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting sniffio (from openai>=0.27.8->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting regex>=2022.1.18 (from tiktoken<1.0,>=0.7->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (2024.8.30)\n",
            "Requirement already satisfied: pytz in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (2024.2)\n",
            "Requirement already satisfied: backports.tempfile in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.0)\n",
            "Requirement already satisfied: pathspec<1.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (0.12.1)\n",
            "Requirement already satisfied: msal<2.0.0,>=1.15.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.31.0)\n",
            "Requirement already satisfied: msal-extensions<=2.0.0,>=0.3.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.2.0)\n",
            "Requirement already satisfied: knack<0.12.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (0.11.0)\n",
            "Requirement already satisfied: azure-core<2.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.31.0)\n",
            "Requirement already satisfied: pkginfo in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.11.1)\n",
            "Requirement already satisfied: argcomplete<4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (3.5.0)\n",
            "Requirement already satisfied: humanfriendly<11.0,>=4.7 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (10.0)\n",
            "Requirement already satisfied: paramiko<4.0.0,>=2.0.8 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (3.5.0)\n",
            "Requirement already satisfied: azure-mgmt-resource<=24.0.0,>=15.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (23.1.1)\n",
            "Requirement already satisfied: azure-mgmt-containerregistry<11,>=8.2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (10.3.0)\n",
            "Requirement already satisfied: azure-mgmt-storage<=22.0.0,>=16.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (21.2.1)\n",
            "Requirement already satisfied: azure-mgmt-keyvault<11.0.0,>=0.40.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (10.3.1)\n",
            "Requirement already satisfied: azure-mgmt-authorization<5,>=0.40.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (4.0.0)\n",
            "Requirement already satisfied: azure-mgmt-network<=26.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (26.0.0)\n",
            "Requirement already satisfied: azure-graphrbac<1.0.0,>=0.40.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (0.61.1)\n",
            "Requirement already satisfied: azure-common<2.0.0,>=1.1.12 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.1.28)\n",
            "Requirement already satisfied: msrest<=0.7.1,>=0.5.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (0.7.1)\n",
            "Requirement already satisfied: msrestazure<=0.7,>=0.4.33 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (0.6.4.post1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.7.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (2.9.0)\n",
            "Requirement already satisfied: ndg-httpsclient<=0.5.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (0.5.1)\n",
            "Requirement already satisfied: SecretStorage<4.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (3.3.3)\n",
            "Requirement already satisfied: jsonpickle<4.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (3.3.0)\n",
            "Requirement already satisfied: contextlib2<22.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (21.6.0)\n",
            "Requirement already satisfied: docker<8.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (7.1.0)\n",
            "Requirement already satisfied: PyJWT<3.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (2.9.0)\n",
            "Requirement already satisfied: adal<=1.2.7,>=1.2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.2.7)\n",
            "Requirement already satisfied: pyopenssl<25.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (24.2.1)\n",
            "Requirement already satisfied: jmespath<2.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from scikit-learn->azureml-rag[faiss,hugging_face]>=0.2.36) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from scikit-learn->azureml-rag[faiss,hugging_face]>=0.2.36) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from scikit-learn->azureml-rag[faiss,hugging_face]>=0.2.36) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from scikit-learn->azureml-rag[faiss,hugging_face]>=0.2.36) (3.5.0)\n",
            "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
            "Collecting torch>=1.11.0 (from sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: Pillow in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36) (10.4.0)\n",
            "Requirement already satisfied: cryptography>=1.1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from adal<=1.2.7,>=1.2.0->azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (43.0.1)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=0.27.8->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.2.2)\n",
            "Requirement already satisfied: six>=1.11.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-core<2.0.0->azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.16.0)\n",
            "Requirement already satisfied: isodate<1.0.0,>=0.6.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-mgmt-authorization<5,>=0.40.0->azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (0.6.1)\n",
            "Requirement already satisfied: azure-mgmt-core<2.0.0,>=1.3.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-mgmt-authorization<5,>=0.40.0->azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.4.0)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>=0.27.8->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai>=0.27.8->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: pygments in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from knack<0.12.0->azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (2.18.0)\n",
            "Requirement already satisfied: tabulate in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from knack<0.12.0->azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (0.9.0)\n",
            "Requirement already satisfied: portalocker<3,>=1.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from msal-extensions<=2.0.0,>=0.3.0->azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (2.10.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from msrest<=0.7.1,>=0.5.1->azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (2.0.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from ndg-httpsclient<=0.5.1->azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (0.6.1)\n",
            "Requirement already satisfied: bcrypt>=3.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from paramiko<4.0.0,>=2.0.8->azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (4.2.0)\n",
            "Requirement already satisfied: pynacl>=1.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from paramiko<4.0.0,>=2.0.8->azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.5.0)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai>=0.27.8->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.27.2 (from pydantic<3,>=1.9.0->openai>=0.27.8->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests[socks]<3.0.0,>=2.19.1->azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.7.1)\n",
            "Requirement already satisfied: jeepney>=0.6 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from SecretStorage<4.0.0->azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (0.8.0)\n",
            "Requirement already satisfied: networkx in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36) (3.3)\n",
            "Requirement already satisfied: jinja2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.2.0 (from torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting sympy==1.13.1 (from torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.41.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36)\n",
            "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: backports.weakref in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from backports.tempfile->azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.0.post1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jsonschema->azureml-dataprep>=5.1->azureml-dataprep[parquet]>=5.1->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jsonschema->azureml-dataprep>=5.1->azureml-dataprep[parquet]>=5.1->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jsonschema->azureml-dataprep>=5.1->azureml-dataprep[parquet]>=5.1->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jsonschema->azureml-dataprep>=5.1->azureml-dataprep[parquet]>=5.1->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (0.20.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from cryptography>=1.1.0->adal<=1.2.7,>=1.2.0->azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.17.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests-oauthlib>=0.5.0->msrest<=0.7.1,>=0.5.1->azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (3.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36) (2.1.5)\n",
            "Requirement already satisfied: pycparser in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=1.1.0->adal<=1.2.7,>=1.2.0->azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (2.22)\n",
            "Downloading azureml_rag-0.2.38-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.29.1-py3-none-any.whl (468 kB)\n",
            "Downloading openai-1.65.1-py3-none-any.whl (472 kB)\n",
            "Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (99 kB)\n",
            "Downloading sentence_transformers-3.4.1-py3-none-any.whl (275 kB)\n",
            "Downloading anyio-4.8.0-py3-none-any.whl (96 kB)\n",
            "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
            "Downloading jiter-0.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\n",
            "Downloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
            "Downloading pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl (766.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
            "Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-cusparselt-cu12, mpmath, faiss-cpu, sympy, sniffio, safetensors, regex, pydantic-core, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mmh3, jiter, h11, distro, annotated-types, tiktoken, pydantic, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface-hub, httpcore, anyio, tokenizers, nvidia-cusolver-cu12, httpx, transformers, torch, openai, sentence-transformers, azureml-rag\n",
            "Successfully installed annotated-types-0.7.0 anyio-4.8.0 azureml-rag-0.2.38 distro-1.9.0 faiss-cpu-1.7.4 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 huggingface-hub-0.29.1 jiter-0.8.2 mmh3-5.1.0 mpmath-1.3.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 openai-1.65.1 pydantic-2.10.6 pydantic-core-2.27.2 regex-2024.11.6 safetensors-0.5.3 sentence-transformers-3.4.1 sniffio-1.3.1 sympy-1.13.1 tiktoken-0.9.0 tokenizers-0.21.0 torch-2.6.0 transformers-4.49.0 triton-3.2.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install the Azure Machine Learning SDK and FAISS-related utilities\n",
        "%pip install azure-ai-ml\n",
        "%pip install -U 'azureml-rag[faiss,hugging_face]>=0.2.36'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **2. Configure Azure Machine Learning Workspace**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get client for AzureML Workspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1740798703730
        }
      },
      "outputs": [],
      "source": [
        "#Write your code here\n",
        "# Import necessary AzureML and authentication libraries\n",
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient\n",
        "from azureml.core import Workspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1736659244442
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting creds.json\n"
          ]
        }
      ],
      "source": [
        "\n",
        "%%writefile creds.json\n",
        "{\n",
        "    \"subscription_id\": \"b113073a-8845-458d-8462-4792938c8faa\",\n",
        "    \"resource_group\": \"default_resorce_group\",\n",
        "    \"workspace_name\": \"pizzasalesworkspace\",\n",
        "    \"account_name\": \"azureai202501\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting config.json\n"
          ]
        }
      ],
      "source": [
        "%%writefile config.json\n",
        "{\n",
        "    \"AZURE_OPENAI_KEY\":\"BispoQ9bDuajs4NvQV6hLb6trvEMh4MdpqtBclvImgiiCkHF4bBnJQQJ99BAACYeBjFXJ3w3AAABACOG99SW\",\n",
        "    \"AZURE_OPENAI_ENDPOINT\":\"https://azureai202501.openai.azure.com/\",\n",
        "    \"AZURE_OPENAI_APIVERSION\":\"2023-05-15\",\n",
        "    \"AZURE_OPENAI_EMBEDDING_MODEL\":\"text-embedding-ada-002\",\n",
        "    \"AZURE_OPENAI_EMBEDING_DEPLOYMENT\":\"text-embedding-ada-002\"\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1740799075331
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found the config file in: creds.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLClient(credential=<azure.identity._credentials.default.DefaultAzureCredential object at 0x7f2b24317fa0>,\n",
            "         subscription_id=b113073a-8845-458d-8462-4792938c8faa,\n",
            "         resource_group_name=default_resorce_group,\n",
            "         workspace_name=pizzasalesworkspace)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Initialize credentials for Azure authentication\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()\n",
        "\n",
        "\n",
        "\n",
        "# Initialize the MLClient to connect with AzureML\n",
        "ml_client = MLClient.from_config(credential=credential, path=\"creds.json\")\n",
        "\n",
        "\n",
        "\n",
        "# Create an AzureML Workspace object\n",
        "ws = Workspace(\n",
        "    subscription_id=ml_client.subscription_id,\n",
        "    resource_group=ml_client.resource_group_name,\n",
        "    workspace_name=ml_client.workspace_name,\n",
        ")\n",
        "\n",
        "\n",
        "# Verify the client and workspace details\n",
        "print(ml_client)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **3. Register the Reports Dataset as a Data Asset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1740799218830
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data asset 'Medical-Diagnosis-list' registered successfully.\n"
          ]
        }
      ],
      "source": [
        "#Write you are code here\n",
        "# Import libraries for data registration\n",
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to the ZIP file containing Tesla annual reports\n",
        "zip_file_path = 'MedicalDiagnosisManuals.zip'\n",
        "\n",
        "\n",
        "# Directory to extract the reports\n",
        "extract_to_directory = './MedicalDiagnosisManual'\n",
        "os.makedirs(extract_to_directory, exist_ok=True)\n",
        "\n",
        "# Extract the ZIP file containing the reports\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to_directory)\n",
        "\n",
        "# Register the extracted data as a Data asset in AzureML\n",
        "local_data_path = extract_to_directory\n",
        "data_asset_name = \"Medical-Diagnosis-list\"\n",
        "data_asset_description = \"A collection of medical manuals used by St. Bernard's Medical Center for embedding generation and knowledge retrieval in the RAG system.\"\n",
        "\n",
        "data_asset = Data(\n",
        "    path=local_data_path,\n",
        "    type=AssetTypes.URI_FOLDER,  # Registering as a folder URI\n",
        "    description=data_asset_description,\n",
        "    name=data_asset_name\n",
        ")\n",
        "\n",
        "# Use the MLClient to register the data asset\n",
        "ml_client.data.create_or_update(data_asset)\n",
        "print(f\"Data asset '{data_asset.name}' registered successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **4. Set Up Azure OpenAI Connection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run the cells under _either_ heading (OpenAI or HuggingFace) to use the respective embedding model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1740799338880
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# # Azure Open AI redentials and the id of the deployed chat model are stored as\n",
        "# # key value pairs in a json file\n",
        "\n",
        "with open('creds.json', 'r') as az_creds:   #Fill the blank with json credentails file \n",
        "     data = az_creds.read()\n",
        "\n",
        "# # Credentials to authenticate to the personalized Open AI model server\n",
        "import json\n",
        "creds = json.loads(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1740801738265
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Azure OpenAI connection created or retrieved successfully: /subscriptions/b113073a-8845-458d-8462-4792938c8faa/resourceGroups/default_resorce_group/providers/Microsoft.MachineLearningServices/workspaces/pizzasalesworkspace/connections/Custom_AzureOpenAI_Connection\n",
            "https://azureai202501.openai.azure.com/\n",
            "ao ai connection{'tags': None, 'location': None, 'id': '/subscriptions/b113073a-8845-458d-8462-4792938c8faa/resourceGroups/default_resorce_group/providers/Microsoft.MachineLearningServices/workspaces/pizzasalesworkspace/connections/Custom_AzureOpenAI_Connection', 'name': 'Custom_AzureOpenAI_Connection', 'type': 'Microsoft.MachineLearningServices/workspaces/connections', 'properties': {'authType': 'ApiKey', 'credentials': None, 'group': 'AzureAI', 'category': 'AzureOpenAI', 'expiryTime': None, 'target': 'https://azureai202501.openai.azure.com/', 'createdByWorkspaceArmId': '/subscriptions/b113073a-8845-458d-8462-4792938c8faa/resourceGroups/default_resorce_group/providers/Microsoft.MachineLearningServices/workspaces/pizzasalesworkspace', 'useWorkspaceManagedIdentity': False, 'isSharedToAll': False, 'sharedUserList': [], 'peRequirement': 'NotRequired', 'peStatus': 'NotApplicable', 'error': None, 'metadata': {'ApiType': 'azure', 'ApiVersion': '2023-05-15', 'DeploymentApiVersion': '2023-10-01-preview'}}, 'systemData': {'createdAt': '2025-03-01T04:02:18.2580061Z', 'createdBy': 'Geeta-Lakshmi_1726943106676@npglazure.onmicrosoft.com', 'createdByType': 'User', 'lastModifiedAt': '2025-03-01T04:02:18.2580061Z', 'lastModifiedBy': 'Geeta-Lakshmi_1726943106676@npglazure.onmicrosoft.com', 'lastModifiedByType': 'User'}}\n"
          ]
        }
      ],
      "source": [
        "from azureml.rag.utils.connections import get_connection_by_name_v2, create_connection_v2\n",
        "\n",
        "# # Define the connection name for Azure OpenAI\n",
        "aoai_connection_name = \"Custom_AzureOpenAI_Connection\"\n",
        "endpoint = creds.get(\"endpoint\", \"https://azureai202501.openai.azure.com/\")  # Use a default or handle missing key\n",
        "api_key = creds.get(\"key\", \"BispoQ9bDuajs4NvQV6hLb6trvEMh4MdpqtBclvImgiiCkHF4bBnJQQJ99BAACYeBjFXJ3w3AAABACOG99SW\")  # Use a default or handle missing key\n",
        "api_version = creds.get(\"api_version\", \"2023-05-15\")  # Use a default or handle missing key\n",
        "\n",
        "\n",
        "# Create the Azure OpenAI connection\n",
        "aoai_connection = create_connection_v2(\n",
        "    workspace=ws,\n",
        "    name=aoai_connection_name,\n",
        "    category=\"AzureOpenAI\",\n",
        "    target=endpoint,\n",
        "    auth_type=\"ApiKey\",\n",
        "    credentials={\"key\": api_key},\n",
        "    metadata={\"ApiType\": \"azure\", \"ApiVersion\": \"2023-05-15\"},\n",
        ")\n",
        "\n",
        "aoai_connection_id = aoai_connection[\"id\"]\n",
        "\n",
        "print(f\"Azure OpenAI connection created or retrieved successfully: {aoai_connection_id}\")\n",
        "print(endpoint)\n",
        "print(f\"ao ai connection{aoai_connection}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1740801745325
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding Model URI: azure_open_ai://openai/deployments/text-embedding-ada-002/model/text-embedding-ada-002\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from azureml.rag.utils.deployment import infer_deployment\n",
        "\n",
        "aoai_embedding_model_name = creds.get(\"AZURE_OPENAI_EMBEDDING_MODEL\", \"text-embedding-ada-002\")\n",
        "aoai_embedding_deployment_name = creds.get(\"AZURE_OPENAI_EMBEDING_DEPLOYMENT\", \"text-embedding-ada-002\")\n",
        "\n",
        "embeddings_model_uri = f\"azure_open_ai://openai/deployments/{aoai_embedding_deployment_name}/model/{aoai_embedding_model_name}\"\n",
        "print(f\"Embedding Model URI: {embeddings_model_uri}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1740802214216
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deployment name in AOAI workspace for model 'text-embedding-ada-002' is not found.\n",
            "Please create a deployment for this model by following the deploy instructions on the resource page for 'https://azureai202501.openai.azure.com/' in Azure Portal.\n"
          ]
        }
      ],
      "source": [
        "from azureml.rag.utils.deployment import infer_deployment\n",
        "\n",
        "aoai_embedding_model_name = \"text-embedding-ada-002\"\n",
        "try:\n",
        "      aoai_embedding_deployment_name = infer_deployment(\n",
        "          aoai_connection, aoai_embedding_model_name\n",
        "      )\n",
        "      print(\n",
        "          f\"Deployment name in AOAI workspace for model '{aoai_embedding_model_name}' is '{aoai_embedding_deployment_name}'\"\n",
        "      )\n",
        "except Exception as e:\n",
        "      print(f\"Deployment name in AOAI workspace for model '{aoai_embedding_model_name}' is not found.\")\n",
        "      print(\n",
        "          f\"Please create a deployment for this model by following the deploy instructions on the resource page for '{aoai_connection['properties']['target']}' in Azure Portal.\"\n",
        "      )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### HuggingFace\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **5. Setup Pipeline to process data into Index**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Define Pipeline Components**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1740799938806
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Write you are code here\n",
        "#Import the MLClient to access the AzureML registry\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "ml_registry = MLClient(credential=credential, registry_name=\"azureml\")\n",
        "\n",
        "# Retrieve components for processing data, generating embeddings, and creating the FAISS index\n",
        "crack_and_chunk_component = ml_registry.components.get(\n",
        "    \"llm_rag_crack_and_chunk\", label=\"latest\"\n",
        ")\n",
        "generate_embeddings_component = ml_registry.components.get(\n",
        "    \"llm_rag_generate_embeddings\", label=\"latest\"\n",
        ")\n",
        "create_faiss_index_component = ml_registry.components.get(\n",
        "    \"llm_rag_create_faiss_index\", label=\"latest\"\n",
        ")\n",
        "register_mlindex_component = ml_registry.components.get(\n",
        "    \"llm_rag_register_mlindex_asset\", label=\"latest\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "gather": {
          "logged": 1740631450067
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n",
            "name: llm_rag_crack_and_chunk\n",
            "version: 0.0.78\n",
            "display_name: LLM - Crack and Chunk Data\n",
            "description: 'Creates chunks no larger than `chunk_size` from `input_data`, extracted\n",
            "  document titles are prepended to each chunk\n",
            "\n",
            "\n",
            "  LLM models have token limits for the prompts passed to them, this is a limiting\n",
            "  factor at embedding time and even more limiting at prompt completion time as only\n",
            "  so much context can be passed along with instructions to the LLM and user queries.\n",
            "\n",
            "  Chunking allows splitting source data of various formats into small but coherent\n",
            "  snippets of information which can be ''packed'' into LLM prompts when asking for\n",
            "  answers to user query related to the source documents.\n",
            "\n",
            "\n",
            "  Supported formats: md, txt, html/htm, pdf, ppt(x), doc(x), xls(x), py\n",
            "\n",
            "  '\n",
            "tags:\n",
            "  Preview: ''\n",
            "type: command\n",
            "inputs:\n",
            "  input_data:\n",
            "    type: uri_folder\n",
            "    description: Uri Folder containing files to be chunked.\n",
            "    optional: false\n",
            "  input_glob:\n",
            "    type: string\n",
            "    optional: true\n",
            "    description: Limit files opened from `input_data`, defaults to '**/*'.\n",
            "  allowed_extensions:\n",
            "    type: string\n",
            "    optional: true\n",
            "    description: Comma separated list of extensions to include, if not provided the\n",
            "      default list of supported extensions will be used. e.g. '.md,.txt,.html,.py,.pdf.'\n",
            "  chunk_size:\n",
            "    type: integer\n",
            "    optional: false\n",
            "    default: '768'\n",
            "    description: Maximum number of tokens to put in each chunk.\n",
            "  chunk_overlap:\n",
            "    type: integer\n",
            "    optional: false\n",
            "    default: '0'\n",
            "    description: Number of tokens to overlap between chunks.\n",
            "  doc_intel_connection_id:\n",
            "    type: string\n",
            "    optional: true\n",
            "    description: Connection id for Document Intelligence service. If provided, will\n",
            "      be used to extract content from .pdf document.\n",
            "  data_source_url:\n",
            "    type: string\n",
            "    optional: true\n",
            "    description: Base URL to join with file paths to create full source file URL for\n",
            "      chunk metadata.\n",
            "  document_path_replacement_regex:\n",
            "    type: string\n",
            "    optional: true\n",
            "    description: 'A JSON string with two fields, ''match_pattern'' and ''replacement_pattern''\n",
            "      to be used with re.sub on the source url. e.g. ''{\"match_pattern\": \"(.*)/articles/(.*)(\\\\.[^.]+)$\",\n",
            "      \"replacement_pattern\": \"\\\\1/\\\\2\"}'' would remove ''/articles'' from the middle\n",
            "      of the url.'\n",
            "  max_sample_files:\n",
            "    type: integer\n",
            "    optional: false\n",
            "    default: '-1'\n",
            "    description: Number of files to chunk. Specify -1 to chunk all documents in input\n",
            "      path.\n",
            "  use_rcts:\n",
            "    type: string\n",
            "    optional: false\n",
            "    default: 'True'\n",
            "    description: Whether to use RecursiveCharacterTextSplitter to split documents\n",
            "      into chunks\n",
            "    enum:\n",
            "    - 'True'\n",
            "    - 'False'\n",
            "  output_format:\n",
            "    type: string\n",
            "    optional: false\n",
            "    default: jsonl\n",
            "    description: Format of the output chunk file\n",
            "    enum:\n",
            "    - csv\n",
            "    - jsonl\n",
            "outputs:\n",
            "  output_chunks:\n",
            "    type: uri_folder\n",
            "    description: Uri Folder containing chunks. Each chunk will be a separate file\n",
            "      in the folder\n",
            "command: python -m azureml.rag.tasks.crack_and_chunk --input_data '${{inputs.input_data}}'\n",
            "  $[[--input_glob '${{inputs.input_glob}}']] $[[--allowed_extensions ${{inputs.allowed_extensions}}]]\n",
            "  --output_chunks ${{outputs.output_chunks}} --chunk_size ${{inputs.chunk_size}} --chunk_overlap\n",
            "  ${{inputs.chunk_overlap}} $[[--doc_intel_connection_id ${{inputs.doc_intel_connection_id}}]]\n",
            "  $[[--data_source_url ${{inputs.data_source_url}}]] $[[--document_path_replacement_regex\n",
            "  '${{inputs.document_path_replacement_regex}}']] --max_sample_files ${{inputs.max_sample_files}}\n",
            "  --use_rcts '${{inputs.use_rcts}}' --output_format ${{inputs.output_format}}\n",
            "environment: azureml://registries/azureml/environments/llm-rag-embeddings/versions/76\n",
            "code: azureml://registries/azureml/codes/2062c1ba-8a97-4ea3-acc3-a7b2e5f8fa58/versions/1\n",
            "resources:\n",
            "  instance_count: 1\n",
            "creation_context:\n",
            "  created_at: '2025-01-02T05:48:55.228512+00:00'\n",
            "  created_by: Microsoft\n",
            "  created_by_type: User\n",
            "  last_modified_at: '2025-01-02T05:48:55.228512+00:00'\n",
            "  last_modified_by: Microsoft\n",
            "  last_modified_by_type: User\n",
            "id: azureml://registries/azureml/components/llm_rag_crack_and_chunk/versions/0.0.78\n",
            "is_deterministic: true\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(crack_and_chunk_component)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Build the AzureML Pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1740799984524
        }
      },
      "outputs": [],
      "source": [
        "# Write you are code here\n",
        "from azure.ai.ml import Input, Output\n",
        "from azure.ai.ml.dsl import pipeline\n",
        "from azure.ai.ml.entities._job.pipeline._io import PipelineInput\n",
        "from typing import Optional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1740800013520
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Utility function for automatic compute configuration\n",
        "def use_automatic_compute(component, instance_count=1, instance_type=\"Standard_NC4as_T4_v3\"):\n",
        "    \"\"\"Configure a component to use automatic compute.\"\"\"\n",
        "    component.set_resources(\n",
        "        instance_count=instance_count,\n",
        "        instance_type=instance_type,\n",
        "        properties={\"compute_specification\": {\"automatic\": True}},\n",
        "    )\n",
        "    return component\n",
        "\n",
        "\n",
        "# Utility function to check if optional pipeline inputs are provided\n",
        "def optional_pipeline_input_provided(input: Optional[PipelineInput]):\n",
        "    \"\"\"Check if optional pipeline inputs are provided.\"\"\"\n",
        "    return input is not None and input._data is not None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1740800210222
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "@pipeline(default_compute=\"serverless\")   #Fill the blank with name of the pipeline and compute\n",
        "def diagnosismanuals_to_faiss(\n",
        "    data_asset_path: str,\n",
        "    embeddings_model: str,\n",
        "    asset_name: str,\n",
        "    chunk_size: int = 1024,    #Provide the chink size \n",
        "    data_source_glob: str = None,\n",
        "    document_path_replacement_regex: str = None,\n",
        "    aoai_connection_id=None,\n",
        "    embeddings_container=None,\n",
        "):\n",
        "    \"\"\"Pipeline to process medical diagnosis manuals and create a FAISS vector index for knowledge retrieval.\"\"\"\n",
        "    \n",
        "    # Step 1: Chunk data into smaller pieces\n",
        "    crack_and_chunk = crack_and_chunk_component(\n",
        "        input_data=Input(type=\"uri_folder\", path=data_asset_path),  # Input data asset and fill the blank with proper type \n",
        "        input_glob=data_source_glob,\n",
        "        chunk_size=chunk_size,\n",
        "        document_path_replacement_regex=document_path_replacement_regex,\n",
        "    )\n",
        "    use_automatic_compute(crack_and_chunk)  # Apply compute configuration\n",
        "\n",
        "    # Step 2: Generate embeddings for the data chunks\n",
        "    generate_embeddings = generate_embeddings_component(\n",
        "        chunks_source=crack_and_chunk.outputs.output_chunks,\n",
        "        embeddings_container=embeddings_container,\n",
        "        embeddings_model=embeddings_model,\n",
        "    )\n",
        "    use_automatic_compute(generate_embeddings)  # Apply compute configuration\n",
        "    \n",
        "    #Optional: Include Azure OpenAI connection ID\n",
        "    if optional_pipeline_input_provided(aoai_connection_id):\n",
        "        generate_embeddings.environment_variables[                        #Fill the blank with proper variable\n",
        "            \"AZUREML_WORKSPACE_CONNECTION_ID_AOAI\"\n",
        "        ] = aoai_connection_id\n",
        "    if optional_pipeline_input_provided(embeddings_container):\n",
        "       generate_embeddings.outputs.embeddings = Output(\n",
        "            type=\"uri_folder\", path=f\"{embeddings_container.path}/{{name}}\"    #Fill the blank with proper type\n",
        "        )\n",
        "\n",
        "    # Step 3: Create a FAISS vector index from embeddings\n",
        "    create_faiss_index = create_faiss_index_component(\n",
        "        embeddings=generate_embeddings.outputs.embeddings,    #Fill the balnk with proper function\n",
        "    )\n",
        "    use_automatic_compute(create_faiss_index)  # Apply compute configuration\n",
        "\n",
        "    # Step 4: Register the FAISS index as an MLIndex asset\n",
        "    register_mlindex = register_mlindex_component(\n",
        "        storage_uri=create_faiss_index.outputs.index,    #Fill the balnk with proper function\n",
        "        asset_name=asset_name\n",
        "    )\n",
        "    use_automatic_compute(register_mlindex) # Apply compute configuration\n",
        "    \n",
        "    return {\n",
        "        \"mlindex_asset_uri\": create_faiss_index.outputs.index,\n",
        "        \"mlindex_asset_id\": register_mlindex.outputs.asset_id,\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **6.Submit the Pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1740800226028
        }
      },
      "outputs": [],
      "source": [
        "# Define the asset name and data source glob pattern\n",
        "asset_name = \"Medical-Diagnosis-list\"  # Name for the FAISS index asset\n",
        "data_source_glob = \"**/*.pdf\"  # Pattern to match input data files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1740800244467
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datastore path: azureml://subscriptions/b113073a-8845-458d-8462-4792938c8faa/resourcegroups/default_resorce_group/workspaces/pizzasalesworkspace/datastores/workspaceblobstore/paths/LocalUpload/a0c35917db9eab5fa2442a9597890dcf/MedicalDiagnosisManual/\n",
            "assest name: Medical-Diagnosis-list\n"
          ]
        }
      ],
      "source": [
        "# Get the input data asset path from the workspace datastore\n",
        "datastore_path = ml_client.data.get(data_asset_name, version=\"1\").path\n",
        "print(f\"Datastore path: {datastore_path}\")\n",
        "print(f\"assest name: {asset_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1740800312521
        }
      },
      "outputs": [],
      "source": [
        "# Create the pipeline job by calling the defined pipeline function\n",
        "pipeline_job = diagnosismanuals_to_faiss(\n",
        "    embeddings_model=embeddings_model_uri,  # URI of the embeddings model\n",
        "    aoai_connection_id=aoai_connection_id,  # Connection ID for Azure OpenAI (optional)\n",
        "    embeddings_container=Input(\n",
        "        type=\"uri_folder\",\n",
        "        path=f\"azureml://datastores/workspaceblobstore/paths/embeddings/{asset_name}\"    \n",
        "    ),  # Path for storing generated embeddings\n",
        "    data_asset_path=Input(\n",
        "        type=\"uri_folder\",\n",
        "        path=datastore_path\n",
        "    ),  # Input data asset path\n",
        "    chunk_size=1024,  # Size of chunks for processing\n",
        "    data_source_glob=data_source_glob,  # Glob pattern for input files\n",
        "    asset_name=asset_name  # Name of the MLIndex asset\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1740800316083
        }
      },
      "outputs": [],
      "source": [
        "# Add properties for better indexing and artifact tracking in the AzureML UI\n",
        "pipeline_job.properties[\"azureml.mlIndexAssetName\"] = asset_name\n",
        "pipeline_job.properties[\"azureml.mlIndexAssetKind\"] = \"faiss\"\n",
        "pipeline_job.properties[\"azureml.mlIndexAssetSource\"] = \"Data asset\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1740800332696
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AZUREML_WORKSPACE_CONNECTION_ID_AOAI is : /subscriptions/b113073a-8845-458d-8462-4792938c8faa/resourceGroups/default_resorce_group/providers/Microsoft.MachineLearningServices/workspaces/pizzasalesworkspace/connections/Custom_AzureOpenAI_Connection\n"
          ]
        }
      ],
      "source": [
        "print(f\"AZUREML_WORKSPACE_CONNECTION_ID_AOAI is : {aoai_connection_id }\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1740800435442
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pipeline submitted successfully! Job ID: /subscriptions/b113073a-8845-458d-8462-4792938c8faa/resourceGroups/default_resorce_group/providers/Microsoft.MachineLearningServices/workspaces/pizzasalesworkspace/jobs/modest_lock_n1nv6040l4\n"
          ]
        }
      ],
      "source": [
        "# Submit the pipeline job for execution\n",
        "submitted_pipeline = ml_client.jobs.create_or_update(pipeline_job)\n",
        "print(f\"Pipeline submitted successfully! Job ID: {submitted_pipeline.id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1740800949515
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RunId: modest_lock_n1nv6040l4\n",
            "Web View: https://ml.azure.com/runs/modest_lock_n1nv6040l4?wsid=/subscriptions/b113073a-8845-458d-8462-4792938c8faa/resourcegroups/default_resorce_group/workspaces/pizzasalesworkspace\n",
            "\n",
            "Streaming logs/azureml/executionlogs.txt\n",
            "========================================\n",
            "\n",
            "[2025-03-01 03:40:38Z] Completing processing run id 7edac6d8-8226-47be-83a4-405f0cdaf056.\n",
            "[2025-03-01 03:40:40Z] Submitting 1 runs, first five are: cf100eef:8109a56a-ca5e-40cb-8870-b1432afed460\n",
            "[2025-03-01 03:48:44Z] Execution of experiment failed, update experiment status and cancel running nodes.\n",
            "\n",
            "Execution Summary\n",
            "=================\n",
            "RunId: modest_lock_n1nv6040l4\n",
            "Web View: https://ml.azure.com/runs/modest_lock_n1nv6040l4?wsid=/subscriptions/b113073a-8845-458d-8462-4792938c8faa/resourcegroups/default_resorce_group/workspaces/pizzasalesworkspace\n"
          ]
        },
        {
          "ename": "JobException",
          "evalue": "Exception : \n {\n    \"error\": {\n        \"code\": \"ServiceError\",\n        \"message\": \"Pipeline has failed child jobs. Failed nodes: /generate_embeddings. For more details and logs, please go to the job detail page and check the child jobs.\",\n        \"message_format\": \"Pipeline has failed child jobs. {0}\",\n        \"message_parameters\": {},\n        \"reference_code\": \"PipelineHasStepJobFailed\",\n        \"details\": []\n    },\n    \"environment\": \"eastus\",\n    \"location\": \"eastus\",\n    \"time\": \"2025-03-01T03:48:44.542734Z\",\n    \"component_name\": \"\"\n} ",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJobException\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Stream the pipeline job logs for real-time monitoring\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mml_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjobs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubmitted_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/tracing/decorator.py:94\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_telemetry/activity.py:289\u001b[0m, in \u001b[0;36mmonitor_with_activity.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tracer\u001b[38;5;241m.\u001b[39mspan():\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m log_activity(\n\u001b[1;32m    287\u001b[0m             logger\u001b[38;5;241m.\u001b[39mpackage_logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions\n\u001b[1;32m    288\u001b[0m         ):\n\u001b[0;32m--> 289\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(logger, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpackage_logger\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m log_activity(logger\u001b[38;5;241m.\u001b[39mpackage_logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions):\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_job_operations.py:818\u001b[0m, in \u001b[0;36mJobOperations.stream\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_pipeline_child_job(job_object):\n\u001b[1;32m    816\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PipelineChildJobError(job_id\u001b[38;5;241m=\u001b[39mjob_object\u001b[38;5;241m.\u001b[39mid)\n\u001b[0;32m--> 818\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream_logs_until_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_runs_operations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_object\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_datastore_operations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequests_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_requests_pipeline\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_job_ops_helper.py:334\u001b[0m, in \u001b[0;36mstream_logs_until_completion\u001b[0;34m(run_operations, job_resource, datastore_operations, raise_exception_on_failed_job, requests_pipeline)\u001b[0m\n\u001b[1;32m    332\u001b[0m         file_handle\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 334\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m JobException(\n\u001b[1;32m    335\u001b[0m             message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException : \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(json\u001b[38;5;241m.\u001b[39mdumps(error, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)),\n\u001b[1;32m    336\u001b[0m             target\u001b[38;5;241m=\u001b[39mErrorTarget\u001b[38;5;241m.\u001b[39mJOB,\n\u001b[1;32m    337\u001b[0m             no_personal_data_message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException raised on failed job.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    338\u001b[0m             error_category\u001b[38;5;241m=\u001b[39mErrorCategory\u001b[38;5;241m.\u001b[39mSYSTEM_ERROR,\n\u001b[1;32m    339\u001b[0m         )\n\u001b[1;32m    341\u001b[0m file_handle\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    342\u001b[0m file_handle\u001b[38;5;241m.\u001b[39mflush()\n",
            "\u001b[0;31mJobException\u001b[0m: Exception : \n {\n    \"error\": {\n        \"code\": \"ServiceError\",\n        \"message\": \"Pipeline has failed child jobs. Failed nodes: /generate_embeddings. For more details and logs, please go to the job detail page and check the child jobs.\",\n        \"message_format\": \"Pipeline has failed child jobs. {0}\",\n        \"message_parameters\": {},\n        \"reference_code\": \"PipelineHasStepJobFailed\",\n        \"details\": []\n    },\n    \"environment\": \"eastus\",\n    \"location\": \"eastus\",\n    \"time\": \"2025-03-01T03:48:44.542734Z\",\n    \"component_name\": \"\"\n} "
          ]
        }
      ],
      "source": [
        "# Stream the pipeline job logs for real-time monitoring\n",
        "ml_client.jobs.stream(submitted_pipeline.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# **Information Retrieval and Response Generation Using LangChain-FAISS and Azure OpenAI**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **1.Installing Required Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "gather": {
          "logged": 1740625461532
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.18-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting dataclasses-json<0.7,>=0.5.7\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Collecting numpy<2,>=1.26.4\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-community) (2.32.3)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Collecting langsmith<0.4,>=0.1.125\n",
            "  Downloading langsmith-0.3.11-py3-none-any.whl (335 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m335.3/335.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting SQLAlchemy<3,>=1.4\n",
            "  Downloading SQLAlchemy-2.0.38-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting langchain<1.0.0,>=0.3.19\n",
            "  Downloading langchain-0.3.19-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-community) (6.0.1)\n",
            "Collecting langchain-core<1.0.0,>=0.3.37\n",
            "  Downloading langchain_core-0.3.40-py3-none-any.whl (414 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m414.3/414.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-community) (2.4.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-community) (3.10.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.3.5)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Collecting typing-inspect<1,>=0.4.0\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain<1.0.0,>=0.3.19->langchain-community) (2.9.2)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.6\n",
            "  Downloading langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.37->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.37->langchain-community) (24.1)\n",
            "Collecting zstandard<0.24.0,>=0.23.0\n",
            "  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14\n",
            "  Downloading orjson-3.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.3/130.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx<1,>=0.23.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.27.2)\n",
            "Collecting requests-toolbelt<2.0.0,>=1.0.0\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dotenv>=0.21.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (1.26.19)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: sniffio in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: anyio in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.6.0)\n",
            "Requirement already satisfied: httpcore==1.* in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.37->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.19->langchain-community) (2.23.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.19->langchain-community) (0.7.0)\n",
            "Collecting mypy-extensions>=0.3.0\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.2.2)\n",
            "Installing collected packages: zstandard, SQLAlchemy, orjson, numpy, mypy-extensions, jsonpatch, httpx-sse, typing-inspect, requests-toolbelt, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain, langchain-community\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-ml 0.6.1 requires enum34, which is not installed.\n",
            "mkl-fft 1.3.8 requires mkl, which is not installed.\n",
            "tensorflow 2.17.0 requires ml-dtypes<0.5.0,>=0.3.1, but you have ml-dtypes 0.5.0 which is incompatible.\n",
            "responsibleai 0.36.0 requires networkx<=2.5, but you have networkx 3.3 which is incompatible.\n",
            "responsibleai 0.36.0 requires numpy<=1.26.2,>=1.17.2, but you have numpy 1.26.4 which is incompatible.\n",
            "raiwidgets 0.36.0 requires numpy<=1.26.2,>=1.17.2, but you have numpy 1.26.4 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.26.4 which is incompatible.\n",
            "fastparquet 2024.5.0 requires pandas>=1.5.0, but you have pandas 1.3.5 which is incompatible.\n",
            "dask-sql 2024.5.0 requires dask[dataframe]>=2024.4.1, but you have dask 2023.2.0 which is incompatible.\n",
            "dask-sql 2024.5.0 requires distributed>=2024.4.1, but you have distributed 2023.2.0 which is incompatible.\n",
            "dask-sql 2024.5.0 requires pandas>=1.4.0, but you have pandas 1.3.5 which is incompatible.\n",
            "dask-expr 1.1.14 requires dask==2024.9.0, but you have dask 2023.2.0 which is incompatible.\n",
            "dask-expr 1.1.14 requires pandas>=2, but you have pandas 1.3.5 which is incompatible.\n",
            "azureml-training-tabular 1.57.0 requires numpy<=1.23.5,>=1.16.0; python_version >= \"3.8\", but you have numpy 1.26.4 which is incompatible.\n",
            "azureml-train-automl-runtime 1.57.0 requires numpy<=1.23.5,>=1.16.0; python_version >= \"3.8\", but you have numpy 1.26.4 which is incompatible.\n",
            "azureml-interpret 1.57.0 requires numpy<=1.23.5; python_version >= \"3.8\", but you have numpy 1.26.4 which is incompatible.\n",
            "azureml-dataset-runtime 1.57.0 requires numpy!=1.19.3,<1.24; sys_platform == \"linux\", but you have numpy 1.26.4 which is incompatible.\n",
            "azureml-automl-runtime 1.57.0 requires numpy<=1.23.5,>=1.16.0; python_version >= \"3.8\", but you have numpy 1.26.4 which is incompatible.\n",
            "azureml-automl-dnn-nlp 1.57.0 requires torch==1.13.1, but you have torch 2.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed SQLAlchemy-2.0.38 dataclasses-json-0.6.7 httpx-sse-0.4.0 jsonpatch-1.33 langchain-0.3.19 langchain-community-0.3.18 langchain-core-0.3.40 langchain-text-splitters-0.3.6 langsmith-0.3.11 mypy-extensions-1.0.0 numpy-1.26.4 orjson-3.10.15 requests-toolbelt-1.0.0 typing-inspect-0.9.0 zstandard-0.23.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting langchain-huggingface\n",
            "  Downloading langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\n",
            "Collecting sentence-transformers>=2.6.0\n",
            "  Downloading sentence_transformers-3.4.1-py3-none-any.whl (275 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.9/275.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting transformers>=4.39.0\n",
            "  Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-huggingface) (0.3.40)\n",
            "Collecting tokenizers>=0.19.1\n",
            "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.23.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-huggingface) (0.24.5)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2023.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (24.1)\n",
            "Requirement already satisfied: filelock in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.15.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.12.2)\n",
            "Requirement already satisfied: requests in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2.32.3)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.3.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (9.0.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.9.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.33)\n",
            "Requirement already satisfied: Pillow in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (9.2.0)\n",
            "Requirement already satisfied: scikit-learn in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.5.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.4.1)\n",
            "Requirement already satisfied: scipy in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.10.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from transformers>=4.39.0->langchain-huggingface) (0.4.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from transformers>=4.39.0->langchain-huggingface) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from transformers>=4.39.0->langchain-huggingface) (2024.7.24)\n",
            "Collecting huggingface-hub>=0.23.0\n",
            "  Downloading huggingface_hub-0.29.1-py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.0/468.0 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonpointer>=1.9 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.23.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (1.26.19)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2024.8.30)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.7)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.20.5)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.1.3.1)\n",
            "Requirement already satisfied: jinja2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (11.4.5.107)\n",
            "Requirement already satisfied: sympy in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.1.105)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (10.3.2.106)\n",
            "Requirement already satisfied: networkx in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.3)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.6.68)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.5.0)\n",
            "Requirement already satisfied: httpcore==1.* in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.3.1)\n",
            "Requirement already satisfied: anyio in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (4.6.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.2.2)\n",
            "Installing collected packages: huggingface-hub, tokenizers, transformers, sentence-transformers, langchain-huggingface\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.24.5\n",
            "    Uninstalling huggingface-hub-0.24.5:\n",
            "      Successfully uninstalled huggingface-hub-0.24.5\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.2\n",
            "    Uninstalling tokenizers-0.15.2:\n",
            "      Successfully uninstalled tokenizers-0.15.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.36.2\n",
            "    Uninstalling transformers-4.36.2:\n",
            "      Successfully uninstalled transformers-4.36.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "azureml-automl-dnn-nlp 1.57.0 requires torch==1.13.1, but you have torch 2.4.1 which is incompatible.\n",
            "azureml-automl-dnn-nlp 1.57.0 requires transformers[sentencepiece,torch]<=4.36.2, but you have transformers 4.49.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface-hub-0.29.1 langchain-huggingface-0.1.2 sentence-transformers-3.4.1 tokenizers-0.21.0 transformers-4.49.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.7-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tiktoken<1,>=0.7 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.39 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-openai) (0.3.40)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-openai) (1.64.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.39->langchain-openai) (0.3.11)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.39->langchain-openai) (2.9.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.39->langchain-openai) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.39->langchain-openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.39->langchain-openai) (6.0.1)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.39->langchain-openai) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.39->langchain-openai) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.6.0)\n",
            "Requirement already satisfied: tqdm>4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.66.4)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.27.2)\n",
            "Requirement already satisfied: requests>=2.26.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.7.24)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai) (1.2.2)\n",
            "Requirement already satisfied: idna>=2.8 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai) (3.7)\n",
            "Requirement already satisfied: httpcore==1.* in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (1.0.5)\n",
            "Requirement already satisfied: certifi in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (2024.8.30)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.39->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.39->langchain-openai) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.39->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.39->langchain-openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.39->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.39->langchain-openai) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (1.26.19)\n",
            "Installing collected packages: langchain-openai\n",
            "Successfully installed langchain-openai-0.3.7\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install the required LangChain and HuggingFace libraries\n",
        "%pip install -U langchain-community\n",
        "%pip install -U langchain-huggingface\n",
        "%pip install -U langchain-openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **2. Setting Up Data Retrieval**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Downloading and Setting Up FAISS Index Assets**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "gather": {
          "logged": 1740625475138
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'./medicaldiagnosisfaissindexasset/'"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import necessary utilities for artifact retrieval\n",
        "import azure.ai.ml._artifacts._artifact_utilities as artifact_utils\n",
        "\n",
        "# Retrieve the path to the latest FAISS index asset from Azure ML\n",
        "data_info = ml_client.data.get(name=asset_name, label=\"latest\").path\n",
        "\n",
        "# Download the FAISS index asset to a local directory\n",
        "artifact_utils.download_artifact_from_aml_uri(\n",
        "    uri=data_info,\n",
        "    destination=\"./medicaldiagnosisfaissindexasset/\",\n",
        "    datastore_operation=ml_client.datastores\n",
        ")\n",
        "\n",
        "# The FAISS index asset will be used for vector-based similarity search."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **3. Loading the FAISS Index**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Loading the FAISS Index and Preparing the Retriever**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "gather": {
          "logged": 1740625478732
        }
      },
      "outputs": [],
      "source": [
        "# Path to the directory containing FAISS index files\n",
        "index_folder_path = \"./medicaldiagnosisfaissindexasset/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "gather": {
          "logged": 1740625486277
        }
      },
      "outputs": [],
      "source": [
        "creds = {\n",
        "    \"AZURE_OPENAI_EMBEDDING_MODEL\": \"text-embedding-ada-002\",  # Replace with your actual model name\n",
        "    \"AZURE_OPENAI_ENDPOINT\": \"https://azureai202501.openai.azure.com/\",\n",
        "    \"AZURE_OPENAI_KY\": \"BispoQ9bDuajs4NvQV6hLb6trvEMh4MdpqtBclvImgiiCkHF4bBnJQQJ99BAACYeBjFXJ3w3AAABACOG99SW\",  # Replace with your actual API key\n",
        "    \"AZURE_OPENAI_APIVERSION\": \"2023-05-15-preview\"  # Replace with the correct API version\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "gather": {
          "logged": 1740625506674
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "embeddings model: client=<openai.resources.embeddings.Embeddings object at 0x7f2446a27520> async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x7f2446889f30> model='text-embedding-ada-002' dimensions=None deployment=None openai_api_version='2023-05-15-preview' openai_api_base=None openai_api_type='azure' openai_proxy=None embedding_ctx_length=8191 openai_api_key=SecretStr('**********') openai_organization=None allowed_special=None disallowed_special=None chunk_size=2048 max_retries=2 request_timeout=None headers=None tiktoken_enabled=True tiktoken_model_name=None show_progress_bar=False model_kwargs={} skip_empty=False default_headers=None default_query=None retry_min_seconds=4 retry_max_seconds=20 http_client=None http_async_client=None check_embedding_ctx_length=True azure_endpoint='https://azureai202501.openai.azure.com/' azure_ad_token=None azure_ad_token_provider=None azure_ad_async_token_provider=None validate_base_url=True\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import AzureOpenAIEmbeddings\n",
        "\n",
        "# Initialize the embedding model with the provided credentials\n",
        "embedding_model = AzureOpenAIEmbeddings(\n",
        "    model=creds[\"AZURE_OPENAI_EMBEDDING_MODEL\"],\n",
        "    azure_endpoint=creds[\"AZURE_OPENAI_ENDPOINT\"],\n",
        "    api_key=creds[\"AZURE_OPENAI_KY\"],\n",
        "    openai_api_version=creds[\"AZURE_OPENAI_APIVERSION\"]\n",
        ")\n",
        "print(f\"embeddings model: {embedding_model}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "gather": {
          "logged": 1740625522876
        }
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Error in faiss::FileIOReader::FileIOReader(const char*) at /project/faiss/faiss/impl/io.cpp:67: Error: 'f' failed: could not open medicaldiagnosisfaissindexasset/index.faiss for reading: No such file or directory",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_4367/402736373.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorstores\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFAISS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the FAISS index and associate it with the embedding model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m retriever = FAISS.load_local(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mfolder_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_folder_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0membeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mallow_dangerous_deserialization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m  \u001b[0;31m# Acknowledge the source of the data for safe loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/langchain_community/vectorstores/faiss.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(cls, folder_path, embeddings, index_name, allow_dangerous_deserialization, **kwargs)\u001b[0m\n\u001b[1;32m   1201\u001b[0m             )\n\u001b[1;32m   1202\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m         \u001b[0;31m# load index separately since it is not picklable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m         \u001b[0mfaiss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdependable_faiss_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1205\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfaiss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34mf\"{index_name}.faiss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m         \u001b[0;31m# load docstore and index_to_docstore_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34mf\"{index_name}.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/faiss/swigfaiss_avx2.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m  10205\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10206\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_swigfaiss_avx2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Error in faiss::FileIOReader::FileIOReader(const char*) at /project/faiss/faiss/impl/io.cpp:67: Error: 'f' failed: could not open medicaldiagnosisfaissindexasset/index.faiss for reading: No such file or directory"
          ]
        }
      ],
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "# Load the FAISS index and associate it with the embedding model\n",
        "retriever = FAISS.load_local(\n",
        "    folder_path=index_folder_path, \n",
        "    embeddings=embedding_model, \n",
        "    allow_dangerous_deserialization=True  # Acknowledge the source of the data for safe loading\n",
        ")\n",
        "\n",
        "# The retriever is now ready to perform similarity searches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "gather": {
          "logged": 1740625533472
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FAISS index saved at ./medicaldiagnosisfaissindexasset/\n"
          ]
        }
      ],
      "source": [
        "print(f\"FAISS index saved at {index_folder_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **4. Performing a Similarity Search**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "gather": {
          "logged": 1740625537513
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'retriever' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[59], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat are the common symptoms and treatments for pulmonary embolism?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Retrieve the top 3 most relevant documents\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241m.\u001b[39msimilarity_search(query, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Display the results\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m results:\n",
            "\u001b[0;31mNameError\u001b[0m: name 'retriever' is not defined"
          ]
        }
      ],
      "source": [
        "# Define a query to test the retriever - you can feel free to pick any disease or medical condition for this \n",
        "\n",
        "query = \"What are the common symptoms and treatments for pulmonary embolism?\"\n",
        "\n",
        "# Retrieve the top 3 most relevant documents\n",
        "results = retriever.similarity_search(query, k=3)\n",
        "\n",
        "# Display the results\n",
        "for doc in results:\n",
        "    print(f\"Document: {doc.page_content}\\nMetadata: {doc.metadata}\")\n",
        "\n",
        "# This step helps validate that the retriever is functioning as expected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## **5: Creating the System and User Prompt Templates**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "gather": {
          "logged": 1740625540987
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Define the system prompt for the Azure OpenAI model\n",
        "qna_system_message = \"\"\"\n",
        "    #Write you are message here\n",
        "\"\"\"\n",
        "# Define the user message template\n",
        "qna_user_message_template = \"\"\"\n",
        "###Context\n",
        "Here are some documents that are relevant to the question mentioned below.\n",
        "{context}\n",
        "\n",
        "###Question\n",
        "{question}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## **6. Generating the Response**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "gather": {
          "logged": 1740625572511
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-openai 0.3.7 requires openai<2.0.0,>=1.58.1, but you have openai 1.2.0 which is incompatible.\n",
            "langchain-openai 0.3.7 requires tiktoken<1,>=0.7, but you have tiktoken 0.6.0 which is incompatible.\n",
            "dask-sql 2024.5.0 requires dask[dataframe]>=2024.4.1, but you have dask 2023.2.0 which is incompatible.\n",
            "dask-sql 2024.5.0 requires distributed>=2024.4.1, but you have distributed 2023.2.0 which is incompatible.\n",
            "dask-sql 2024.5.0 requires pandas>=1.4.0, but you have pandas 1.3.5 which is incompatible.\n",
            "azureml-rag 0.2.38 requires tiktoken<1.0,>=0.7, but you have tiktoken 0.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install the rquired packages\n",
        "%pip install openai==1.2.0 tiktoken==0.6 session-info --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "gather": {
          "logged": 1740625590173
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import json\n",
        "import tiktoken\n",
        "import pandas as pd\n",
        "from openai import AzureOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "gather": {
          "logged": 1740625593210
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Load Azure OpenAI credentials\n",
        "with open('config.json', 'r') as az_creds:\n",
        "    data = az_creds.read()\n",
        "\n",
        "creds = json.loads(data)\n",
        "\n",
        "#print(creds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1737178038645
        }
      },
      "outputs": [],
      "source": [
        "#endpoint = creds.get(\"endpoint\", \"https://azureai2025.openai.azure.com/\")  # Use a default or handle missing key\n",
        "#api_key = creds.get(\"key\", \"BispoQ9bDuajs4NvQV6hLb6trvEMh4MdpqtBclvImgiiCkHF4bBnJQQJ99BAACYeBjFXJ3w3AAABACOG99SW\")  # Use a default or handle missing key\n",
        "#api_version = creds.get(\"api_version\", \"2024-05-01-preview\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "gather": {
          "logged": 1740625598277
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'endpoint'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[64], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize the Azure OpenAI client\u001b[39;00m\n\u001b[1;32m      2\u001b[0m client \u001b[38;5;241m=\u001b[39m AzureOpenAI(\n\u001b[0;32m----> 3\u001b[0m     azure_endpoint\u001b[38;5;241m=\u001b[39m\u001b[43mcreds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mendpoint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[1;32m      4\u001b[0m     api_key\u001b[38;5;241m=\u001b[39mcreds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      5\u001b[0m     api_version\u001b[38;5;241m=\u001b[39mcreds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_version\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      6\u001b[0m )\n",
            "\u001b[0;31mKeyError\u001b[0m: 'endpoint'"
          ]
        }
      ],
      "source": [
        "# Initialize the Azure OpenAI client\n",
        "client = AzureOpenAI(\n",
        "    azure_endpoint=creds[\"endpoint\"],\n",
        "    api_key=creds[\"key\"],\n",
        "    api_version=creds[\"api_version\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "gather": {
          "logged": 1740625603461
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def generate_rag_response(user_input):\n",
        "    # Retrieve relevant document chunks\n",
        "    relevant_document_chunks = retriever.similarity_search(user_input, k=3)\n",
        "    context_list = [d.page_content for d in relevant_document_chunks]\n",
        "\n",
        "    # Combine document chunks into a single context\n",
        "    context_for_query = \". \".join(context_list)\n",
        "\n",
        "    # Compose the prompt\n",
        "    prompt = [\n",
        "        {'role': 'system', 'content': qna_system_message},\n",
        "        {'role': 'user', 'content': qna_user_message_template.format(\n",
        "            context=context_for_query,\n",
        "            question=user_input\n",
        "            )\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Generate the response using Azure OpenAI\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=creds[\"CHATGPT_MODEL\"],\n",
        "            messages=prompt,\n",
        "            temperature=0\n",
        "        )\n",
        "\n",
        "        # Extract and print the model's response\n",
        "        response = response.choices[0].message.content.strip()\n",
        "    except Exception as e:\n",
        "        response = f'Sorry, I encountered the following error: \\n {e}'\n",
        "\n",
        "\n",
        "    print(response)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Question 1: What is the protocol for managing sepsis in a critical care unit?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "gather": {
          "logged": 1740625606526
        }
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'retriever' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[66], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the protocol for managing sepsis in a critical care unit?\u001b[39m\u001b[38;5;124m\"\u001b[39m    \u001b[38;5;66;03m# Enter the question to be answered by the system here \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mgenerate_rag_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[65], line 3\u001b[0m, in \u001b[0;36mgenerate_rag_response\u001b[0;34m(user_input)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_rag_response\u001b[39m(user_input):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Retrieve relevant document chunks\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     relevant_document_chunks \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241m.\u001b[39msimilarity_search(user_input, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      4\u001b[0m     context_list \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m relevant_document_chunks]\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Combine document chunks into a single context\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'retriever' is not defined"
          ]
        }
      ],
      "source": [
        "user_input = \"What is the protocol for managing sepsis in a critical care unit?\"    # Enter the question to be answered by the system here \n",
        "generate_rag_response(user_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Question 2: What are the common symptoms for appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "gather": {
          "logged": 1737872737428
        }
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'retriever' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[104], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat are the common symptoms for appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?\u001b[39m\u001b[38;5;124m\"\u001b[39m   \u001b[38;5;66;03m# Enter the question to be answered by the system here \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mgenerate_rag_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[102], line 3\u001b[0m, in \u001b[0;36mgenerate_rag_response\u001b[0;34m(user_input)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_rag_response\u001b[39m(user_input):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Retrieve relevant document chunks\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     relevant_document_chunks \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241m.\u001b[39msimilarity_search(user_input, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      4\u001b[0m     context_list \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m relevant_document_chunks]\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Combine document chunks into a single context\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'retriever' is not defined"
          ]
        }
      ],
      "source": [
        "user_input = \"What are the common symptoms for appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?\"   # Enter the question to be answered by the system here \n",
        "generate_rag_response(user_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Question 3: What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1737178038767
        }
      },
      "outputs": [],
      "source": [
        "user_input = \"What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?\"   # Enter the question to be answered by the system here \n",
        "generate_rag_response(user_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Question 4:  What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1737178038790
        }
      },
      "outputs": [],
      "source": [
        "user_input = \"What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?\"   # Enter the question to be answered by the system here \n",
        "generate_rag_response(user_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Question 5: What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1737178038821
        }
      },
      "outputs": [],
      "source": [
        "user_input = \"What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?\"   # Enter the question to be answered by the system here \n",
        "generate_rag_response(user_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Power Ahead!"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
