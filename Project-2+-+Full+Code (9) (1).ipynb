{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project 2**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Business Use Case**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Problem Statement:**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the fast-paced environment of healthcare centers, healthcare professionals often face the challenge of quick and accurate diagnosis of patients while managing an ever-increasing volume of medical information. Ensuring that healthcare providers have access to the latest and most comprehensive medical knowledge is crucial for improving patient outcomes and reducing the time needed to make informed decisions.\n",
        "\n",
        "There are multiple challenges that these professionals encounter daily, a few being\n",
        "\n",
        "- Information Overload: Medical professionals need to go through vast amounts of data and research to make accurate diagnoses and treatment plans. This can be overwhelming and time-consuming.\n",
        "- Efficiency: For overall patient care and quality health outcomes, quick and accurate diagnosis is vital, especially in emergency situations.\n",
        "- Access to Trusted Knowledge: In the ever-evolving healthcare industry, providing access to reliable and up-to-date medical information from renowned manuals and research papers is essential for maintaining high standards of care.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Objective:**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "A renowned chain of hospitals has decided to leverage AI to build a state-of-the-art solution to help healthcare professionals overcome the aforementioned challenges. They have recruited you as an AI specialist and tasked you with building a RAG-based AI solution that leverages renowned medical manuals as its knowledge base. This AI system will act as a POC towards an end product that’ll assist healthcare professionals in making better, quicker, and more accurate diagnoses, ultimately leading to faster patient resolutions and enabling better patient outcomes by reducing errors in diagnosis, saving valuable time for information retrieval, and standardizing care practices across the board."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Questions:**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Diagnostic Assistance**: \"What are the common symptoms and treatments for pulmonary embolism?\"\n",
        "\n",
        "**2. Drug Information**: \"Can you provide the trade names of medications used for treating hypertension?\"\n",
        "\n",
        "**3. Treatment Plans**: \"What are the first-line options and alternatives for managing rheumatoid arthritis?\"\n",
        "\n",
        "**4. Specialty Knowledge**: \"What are the diagnostic steps for suspected endocrine disorders?\"\n",
        "\n",
        "**5. Critical Care Protocols**: \"What is the protocol for managing sepsis in a critical care unit?\""
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **How This Application Empowers Professionals and Elevates Healthcare Organizations**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Enhanced Diagnostic Accuracy:**\n",
        "Provides evidence-based insights for better diagnosis and treatment.\n",
        "\n",
        "- **Time Efficiency:**\n",
        "Instantly retrieves critical information, saving valuable time.\n",
        "\n",
        "- **Improved Patient Care:**\n",
        "Ensures informed decisions with up-to-date medical knowledge.\n",
        "\n",
        "- **Cost-Effective Operations:**\n",
        "Reduces redundant tests and consultation delays, lowering costs.\n",
        "\n",
        "- **Knowledge Empowerment:**\n",
        "Keeps doctors updated on the latest advancements.\n",
        "\n",
        "- **Competitive Edge for the Hospital:**\n",
        "Positions the hospital as a leader in healthcare innovation.\n",
        "\n",
        "This collaboration between St. Bernard’s Medical Center and InnoviTech Solutions highlights the transformative potential of AI in revolutionizing healthcare."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Install and Import Required Libraries**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the Azure Machine Learning SDK and FAISS-related utilities\n",
        "%pip install azure-ai-ml\n",
        "%pip install -U 'azureml-rag[faiss,hugging_face]>=0.2.36'"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: azure-ai-ml in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (1.24.0)\nRequirement already satisfied: azure-storage-file-datalake>=12.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (12.18.1)\nRequirement already satisfied: azure-storage-blob>=12.10.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (12.24.1)\nRequirement already satisfied: azure-common>=1.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (1.1.28)\nRequirement already satisfied: pydash>=6.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (8.0.5)\nRequirement already satisfied: pyjwt in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (2.4.0)\nRequirement already satisfied: colorama in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (0.4.6)\nRequirement already satisfied: jsonschema>=4.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (4.23.0)\nRequirement already satisfied: azure-core>=1.23.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (1.30.2)\nRequirement already satisfied: azure-storage-file-share in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (12.20.1)\nRequirement already satisfied: tqdm in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (4.66.4)\nRequirement already satisfied: isodate in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (0.6.1)\nRequirement already satisfied: azure-mgmt-core>=1.3.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (1.4.0)\nRequirement already satisfied: msrest>=0.6.18 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (0.7.1)\nRequirement already satisfied: strictyaml in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (1.7.3)\nRequirement already satisfied: typing-extensions in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (4.12.2)\nRequirement already satisfied: azure-monitor-opentelemetry in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (1.6.4)\nRequirement already satisfied: pyyaml>=5.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (6.0.1)\nRequirement already satisfied: marshmallow>=3.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (3.26.0)\nRequirement already satisfied: six>=1.11.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-core>=1.23.0->azure-ai-ml) (1.16.0)\nRequirement already satisfied: requests>=2.21.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-core>=1.23.0->azure-ai-ml) (2.32.3)\nRequirement already satisfied: cryptography>=2.1.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-storage-blob>=12.10.0->azure-ai-ml) (38.0.4)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (0.35.1)\nRequirement already satisfied: attrs>=22.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (24.2.0)\nRequirement already satisfied: rpds-py>=0.7.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (0.19.1)\nRequirement already satisfied: packaging>=17.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from marshmallow>=3.5->azure-ai-ml) (24.1)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from msrest>=0.6.18->azure-ai-ml) (2024.8.30)\nRequirement already satisfied: requests-oauthlib>=0.5.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from msrest>=0.6.18->azure-ai-ml) (2.0.0)\nRequirement already satisfied: opentelemetry-instrumentation-psycopg2~=0.49b0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-monitor-opentelemetry->azure-ai-ml) (0.50b0)\nRequirement already satisfied: azure-core-tracing-opentelemetry~=1.0.0b11 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-monitor-opentelemetry->azure-ai-ml) (1.0.0b11)\nRequirement already satisfied: opentelemetry-instrumentation-flask~=0.49b0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-monitor-opentelemetry->azure-ai-ml) (0.50b0)\nRequirement already satisfied: opentelemetry-instrumentation-urllib3~=0.49b0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-monitor-opentelemetry->azure-ai-ml) (0.50b0)\nRequirement already satisfied: opentelemetry-instrumentation-fastapi~=0.49b0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-monitor-opentelemetry->azure-ai-ml) (0.50b0)\nRequirement already satisfied: opentelemetry-resource-detector-azure~=0.1.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-monitor-opentelemetry->azure-ai-ml) (0.1.5)\nRequirement already satisfied: azure-monitor-opentelemetry-exporter~=1.0.0b31 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-monitor-opentelemetry->azure-ai-ml) (1.0.0b33)\nRequirement already satisfied: opentelemetry-instrumentation-django~=0.49b0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-monitor-opentelemetry->azure-ai-ml) (0.50b0)\nRequirement already satisfied: opentelemetry-sdk~=1.28 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-monitor-opentelemetry->azure-ai-ml) (1.29.0)\nRequirement already satisfied: opentelemetry-instrumentation-urllib~=0.49b0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-monitor-opentelemetry->azure-ai-ml) (0.50b0)\nRequirement already satisfied: opentelemetry-instrumentation-requests~=0.49b0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-monitor-opentelemetry->azure-ai-ml) (0.50b0)\nRequirement already satisfied: python-dateutil>=2.6.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from strictyaml->azure-ai-ml) (2.9.0.post0)\nRequirement already satisfied: opentelemetry-api<2.0.0,>=1.12.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-core-tracing-opentelemetry~=1.0.0b11->azure-monitor-opentelemetry->azure-ai-ml) (1.29.0)\nRequirement already satisfied: psutil~=5.9 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-monitor-opentelemetry-exporter~=1.0.0b31->azure-monitor-opentelemetry->azure-ai-ml) (5.9.3)\nRequirement already satisfied: fixedint==0.1.6 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-monitor-opentelemetry-exporter~=1.0.0b31->azure-monitor-opentelemetry->azure-ai-ml) (0.1.6)\nRequirement already satisfied: cffi>=1.12 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from cryptography>=2.1.4->azure-storage-blob>=12.10.0->azure-ai-ml) (1.16.0)\nRequirement already satisfied: opentelemetry-instrumentation==0.50b0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-instrumentation-django~=0.49b0->azure-monitor-opentelemetry->azure-ai-ml) (0.50b0)\nRequirement already satisfied: opentelemetry-util-http==0.50b0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-instrumentation-django~=0.49b0->azure-monitor-opentelemetry->azure-ai-ml) (0.50b0)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-instrumentation-django~=0.49b0->azure-monitor-opentelemetry->azure-ai-ml) (0.50b0)\nRequirement already satisfied: opentelemetry-instrumentation-wsgi==0.50b0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-instrumentation-django~=0.49b0->azure-monitor-opentelemetry->azure-ai-ml) (0.50b0)\nRequirement already satisfied: wrapt<2.0.0,>=1.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.50b0->opentelemetry-instrumentation-django~=0.49b0->azure-monitor-opentelemetry->azure-ai-ml) (1.14.1)\nRequirement already satisfied: deprecated>=1.2.6 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-semantic-conventions==0.50b0->opentelemetry-instrumentation-django~=0.49b0->azure-monitor-opentelemetry->azure-ai-ml) (1.2.14)\nRequirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-api<2.0.0,>=1.12.0->azure-core-tracing-opentelemetry~=1.0.0b11->azure-monitor-opentelemetry->azure-ai-ml) (8.2.0)\nRequirement already satisfied: opentelemetry-instrumentation-asgi==0.50b0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi~=0.49b0->azure-monitor-opentelemetry->azure-ai-ml) (0.50b0)\nRequirement already satisfied: asgiref~=3.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi~=0.49b0->azure-monitor-opentelemetry->azure-ai-ml) (3.8.1)\nRequirement already satisfied: opentelemetry-instrumentation-dbapi==0.50b0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-instrumentation-psycopg2~=0.49b0->azure-monitor-opentelemetry->azure-ai-ml) (0.50b0)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (1.26.19)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (3.7)\nRequirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.18->azure-ai-ml) (3.2.2)\nRequirement already satisfied: pycparser in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob>=12.10.0->azure-ai-ml) (2.22)\nRequirement already satisfied: zipp>=0.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api<2.0.0,>=1.12.0->azure-core-tracing-opentelemetry~=1.0.0b11->azure-monitor-opentelemetry->azure-ai-ml) (3.19.2)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: azureml-rag[faiss,hugging_face]>=0.2.36 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (0.2.37.3)\n\u001b[33mWARNING: azureml-rag 0.2.37.3 does not provide the extra 'hugging_face'\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: pyyaml<7.0.0,>=5.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-rag[faiss,hugging_face]>=0.2.36) (6.0.1)\nRequirement already satisfied: requests in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-rag[faiss,hugging_face]>=0.2.36) (2.32.3)\nRequirement already satisfied: tiktoken<1.0,>=0.7 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-rag[faiss,hugging_face]>=0.2.36) (0.8.0)\nRequirement already satisfied: cloudpickle in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-rag[faiss,hugging_face]>=0.2.36) (2.2.1)\nRequirement already satisfied: azureml-dataprep[parquet]>=5.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-rag[faiss,hugging_face]>=0.2.36) (5.1.6)\nRequirement already satisfied: openai>=0.27.8 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-rag[faiss,hugging_face]>=0.2.36) (1.60.2)\nRequirement already satisfied: azureml-fsspec in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-rag[faiss,hugging_face]>=0.2.36) (1.3.1)\nRequirement already satisfied: fsspec~=2023.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-rag[faiss,hugging_face]>=0.2.36) (2023.10.0)\nRequirement already satisfied: mmh3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-rag[faiss,hugging_face]>=0.2.36) (5.1.0)\nRequirement already satisfied: azureml-core in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-rag[faiss,hugging_face]>=0.2.36) (1.57.0)\nRequirement already satisfied: faiss-cpu~=1.7.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-rag[faiss,hugging_face]>=0.2.36) (1.7.4)\nRequirement already satisfied: jsonschema in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-dataprep[parquet]>=5.1->azureml-rag[faiss,hugging_face]>=0.2.36) (4.23.0)\nRequirement already satisfied: azureml-dataprep-rslex~=2.22.2dev0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-dataprep[parquet]>=5.1->azureml-rag[faiss,hugging_face]>=0.2.36) (2.22.2)\nRequirement already satisfied: azure-identity>=1.7.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-dataprep[parquet]>=5.1->azureml-rag[faiss,hugging_face]>=0.2.36) (1.17.1)\nRequirement already satisfied: azureml-dataprep-native<42.0.0,>=41.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-dataprep[parquet]>=5.1->azureml-rag[faiss,hugging_face]>=0.2.36) (41.0.0)\nRequirement already satisfied: pyarrow>=0.17.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-dataprep[parquet]>=5.1->azureml-rag[faiss,hugging_face]>=0.2.36) (14.0.2)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from openai>=0.27.8->azureml-rag[faiss,hugging_face]>=0.2.36) (2.9.2)\nRequirement already satisfied: typing-extensions<5,>=4.11 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from openai>=0.27.8->azureml-rag[faiss,hugging_face]>=0.2.36) (4.12.2)\nRequirement already satisfied: tqdm>4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from openai>=0.27.8->azureml-rag[faiss,hugging_face]>=0.2.36) (4.66.4)\nRequirement already satisfied: httpx<1,>=0.23.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from openai>=0.27.8->azureml-rag[faiss,hugging_face]>=0.2.36) (0.27.2)\nRequirement already satisfied: jiter<1,>=0.4.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from openai>=0.27.8->azureml-rag[faiss,hugging_face]>=0.2.36) (0.8.2)\nRequirement already satisfied: distro<2,>=1.7.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from openai>=0.27.8->azureml-rag[faiss,hugging_face]>=0.2.36) (1.9.0)\nRequirement already satisfied: anyio<5,>=3.5.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from openai>=0.27.8->azureml-rag[faiss,hugging_face]>=0.2.36) (4.6.0)\nRequirement already satisfied: sniffio in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from openai>=0.27.8->azureml-rag[faiss,hugging_face]>=0.2.36) (1.3.1)\nRequirement already satisfied: regex>=2022.1.18 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tiktoken<1.0,>=0.7->azureml-rag[faiss,hugging_face]>=0.2.36) (2024.7.24)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests->azureml-rag[faiss,hugging_face]>=0.2.36) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests->azureml-rag[faiss,hugging_face]>=0.2.36) (1.26.19)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests->azureml-rag[faiss,hugging_face]>=0.2.36) (2024.8.30)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests->azureml-rag[faiss,hugging_face]>=0.2.36) (3.7)\nRequirement already satisfied: azure-mgmt-network<=26.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (25.1.0)\nRequirement already satisfied: paramiko<4.0.0,>=2.0.8 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (3.4.0)\nRequirement already satisfied: azure-common<2.0.0,>=1.1.12 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (1.1.28)\nRequirement already satisfied: ndg-httpsclient<=0.5.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (0.5.1)\nRequirement already satisfied: azure-mgmt-resource<=24.0.0,>=15.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (23.1.1)\nRequirement already satisfied: azure-graphrbac<1.0.0,>=0.40.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (0.60.0)\nRequirement already satisfied: azure-core<2.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (1.30.2)\nRequirement already satisfied: azure-mgmt-keyvault<11.0.0,>=0.40.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (10.3.0)\nRequirement already satisfied: docker<8.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (7.1.0)\nRequirement already satisfied: backports.tempfile in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (1.0)\nRequirement already satisfied: knack<0.12.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (0.11.0)\nRequirement already satisfied: contextlib2<22.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (21.6.0)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.7.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (2.9.0.post0)\nRequirement already satisfied: pyopenssl<25.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (23.0.0)\nRequirement already satisfied: jmespath<2.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (0.10.0)\nRequirement already satisfied: msrest<=0.7.1,>=0.5.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (0.7.1)\nRequirement already satisfied: argcomplete<4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (3.3.0)\nRequirement already satisfied: msal<2.0.0,>=1.15.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (1.30.0)\nRequirement already satisfied: jsonpickle<4.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (3.2.2)\nRequirement already satisfied: msrestazure<=0.7,>=0.4.33 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (0.6.4.post1)\nRequirement already satisfied: azure-mgmt-authorization<5,>=0.40.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (4.0.0)\nRequirement already satisfied: SecretStorage<4.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (3.3.3)\nRequirement already satisfied: pathspec<1.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (0.12.1)\nRequirement already satisfied: PyJWT<3.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (2.4.0)\nRequirement already satisfied: pkginfo in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (1.11.1)\nRequirement already satisfied: pytz in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (2022.5)\nRequirement already satisfied: msal-extensions<=2.0.0,>=0.3.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (1.2.0)\nRequirement already satisfied: humanfriendly<11.0,>=4.7 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (10.0)\nRequirement already satisfied: packaging<=25.0,>=20.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (24.1)\nRequirement already satisfied: adal<=1.2.7,>=1.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (1.2.7)\nRequirement already satisfied: azure-mgmt-containerregistry<11,>=8.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (10.3.0)\nRequirement already satisfied: azure-mgmt-storage<=22.0.0,>=16.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (21.2.0)\nRequirement already satisfied: cryptography>=1.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from adal<=1.2.7,>=1.2.0->azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (38.0.4)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=0.27.8->azureml-rag[faiss,hugging_face]>=0.2.36) (1.2.2)\nRequirement already satisfied: six>=1.11.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-core<2.0.0->azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (1.16.0)\nRequirement already satisfied: isodate<1.0.0,>=0.6.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-mgmt-authorization<5,>=0.40.0->azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (0.6.1)\nRequirement already satisfied: azure-mgmt-core<2.0.0,>=1.3.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-mgmt-authorization<5,>=0.40.0->azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (1.4.0)\nRequirement already satisfied: httpcore==1.* in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai>=0.27.8->azureml-rag[faiss,hugging_face]>=0.2.36) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=0.27.8->azureml-rag[faiss,hugging_face]>=0.2.36) (0.14.0)\nRequirement already satisfied: tabulate in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from knack<0.12.0->azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (0.9.0)\nRequirement already satisfied: pygments in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from knack<0.12.0->azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (2.18.0)\nRequirement already satisfied: portalocker<3,>=1.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from msal-extensions<=2.0.0,>=0.3.0->azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (2.10.1)\nRequirement already satisfied: requests-oauthlib>=0.5.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from msrest<=0.7.1,>=0.5.1->azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (2.0.0)\nRequirement already satisfied: pyasn1>=0.1.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from ndg-httpsclient<=0.5.1->azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (0.6.0)\nRequirement already satisfied: bcrypt>=3.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from paramiko<4.0.0,>=2.0.8->azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (4.2.0)\nRequirement already satisfied: pynacl>=1.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from paramiko<4.0.0,>=2.0.8->azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (1.5.0)\nRequirement already satisfied: numpy>=1.16.6 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pyarrow>=0.17.0->azureml-dataprep[parquet]>=5.1->azureml-rag[faiss,hugging_face]>=0.2.36) (1.23.5)\nRequirement already satisfied: pydantic-core==2.23.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai>=0.27.8->azureml-rag[faiss,hugging_face]>=0.2.36) (2.23.4)\nRequirement already satisfied: annotated-types>=0.6.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai>=0.27.8->azureml-rag[faiss,hugging_face]>=0.2.36) (0.7.0)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests->azureml-rag[faiss,hugging_face]>=0.2.36) (1.7.1)\nRequirement already satisfied: jeepney>=0.6 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from SecretStorage<4.0.0->azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (0.8.0)\nRequirement already satisfied: backports.weakref in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from backports.tempfile->azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (1.0.post1)\nRequirement already satisfied: referencing>=0.28.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema->azureml-dataprep[parquet]>=5.1->azureml-rag[faiss,hugging_face]>=0.2.36) (0.35.1)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema->azureml-dataprep[parquet]>=5.1->azureml-rag[faiss,hugging_face]>=0.2.36) (2023.12.1)\nRequirement already satisfied: attrs>=22.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema->azureml-dataprep[parquet]>=5.1->azureml-rag[faiss,hugging_face]>=0.2.36) (24.2.0)\nRequirement already satisfied: rpds-py>=0.7.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema->azureml-dataprep[parquet]>=5.1->azureml-rag[faiss,hugging_face]>=0.2.36) (0.19.1)\nRequirement already satisfied: cffi>=1.12 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from cryptography>=1.1.0->adal<=1.2.7,>=1.2.0->azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (1.16.0)\nRequirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests-oauthlib>=0.5.0->msrest<=0.7.1,>=0.5.1->azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (3.2.2)\nRequirement already satisfied: pycparser in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=1.1.0->adal<=1.2.7,>=1.2.0->azureml-core->azureml-rag[faiss,hugging_face]>=0.2.36) (2.22)\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1738122365272
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Configure Azure Machine Learning Workspace**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get client for AzureML Workspace"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Write you are code here\n",
        "# Import necessary AzureML and authentication libraries\n",
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient\n",
        "from azureml.core import Workspace"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1738122386415
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define workspace configuration (replace with your details)\n",
        "workspace_config = {\n",
        "    \"subscription_id\": \"b113073a-8845-458d-8462-4792938c8faa\",  # Replace with your Azure subscription ID\n",
        "    \"resource_group\": \"default_resorce_group\",    # Replace with your Azure resource group name\n",
        "    \"workspace_name\": \"pizzasalesworkspace\",        # Replace with your AzureML workspace name\n",
        "}"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1738122400046
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%writefile workspace.json\n",
        "{\n",
        "    \"subscription_id\": \"b113073a-8845-458d-8462-4792938c8faa\",\n",
        "    \"resource_group\": \"default_resorce_group\",\n",
        "    \"workspace_name\": \"pizzasalesworkspace\"\n",
        "}"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting workspace.json\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1736659244442
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile config.json\n",
        "{\n",
        "    \"api_key\":\"BispoQ9bDuajs4NvQV6hLb6trvEMh4MdpqtBclvImgiiCkHF4bBnJQQJ99BAACYeBjFXJ3w3AAABACOG99SW\",\n",
        "    \"api_endpoint\":\"https://azureai202501.openai.azure.com/\",\n",
        "    \"api_version\":\"2024-05-01-preview\"\n",
        "}"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting config.json\n"
        }
      ],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize credentials for Azure authentication\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1738122464285
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize credentials for Azure authentication\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()\n",
        "\n",
        "# Initialize the MLClient to connect with AzureML\n",
        "ml_client = MLClient.from_config(credential=credential, path=\"workspace.json\")\n",
        "\n",
        "# Create an AzureML Workspace object\n",
        "ws = Workspace(\n",
        "    subscription_id=ml_client.subscription_id,\n",
        "    resource_group=ml_client.resource_group_name,\n",
        "    workspace_name=ml_client.workspace_name,\n",
        ")\n",
        "\n",
        "# Verify the client and workspace details\n",
        "print(ml_client)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: workspace.json\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "MLClient(credential=<azure.identity._credentials.default.DefaultAzureCredential object at 0x7fb135dcd5d0>,\n         subscription_id=b113073a-8845-458d-8462-4792938c8faa,\n         resource_group_name=default_resorce_group,\n         workspace_name=pizzasalesworkspace)\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1738122472588
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## **3. Register the Reports Dataset as a Data Asset**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Write you are code here\n",
        "# Import libraries for data registration\n",
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to the ZIP file containing Tesla annual reports\n",
        "zip_file_path = 'MedicalDiagnosisManuals.zip'\n",
        "\n",
        "\n",
        "# Directory to extract the reports\n",
        "extract_to_directory = './MedicalDiagnosisManual'\n",
        "os.makedirs(extract_to_directory, exist_ok=True)\n",
        "\n",
        "# Extract the ZIP file containing the reports\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to_directory)\n",
        "\n",
        "# Register the extracted data as a Data asset in AzureML\n",
        "local_data_path = extract_to_directory\n",
        "data_asset_name = \"Medical-Diagnosis-list\"\n",
        "data_asset_description = \"A collection of medical manuals used by St. Bernard's Medical Center for embedding generation and knowledge retrieval in the RAG system.\"\n",
        "\n",
        "data_asset = Data(\n",
        "    path=local_data_path,\n",
        "    type=AssetTypes.URI_FOLDER,  # Registering as a folder URI\n",
        "    description=data_asset_description,\n",
        "    name=data_asset_name\n",
        ")\n",
        "\n",
        "# Use the MLClient to register the data asset\n",
        "ml_client.data.create_or_update(data_asset)\n",
        "print(f\"Data asset '{data_asset.name}' registered successfully.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Data asset 'Medical-Diagnosis-list' registered successfully.\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1738122480545
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Set Up Azure OpenAI Connection**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the cells under _either_ heading (OpenAI or HuggingFace) to use the respective embedding model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### OpenAI"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# # Azure Open AI redentials and the id of the deployed chat model are stored as\n",
        "# # key value pairs in a json file\n",
        "\n",
        "with open('workspace.json', 'r') as az_creds:   #Fill the blank with json credentails file \n",
        "     data = az_creds.read()\n",
        "\n",
        "# # Credentials to authenticate to the personalized Open AI model server\n",
        "import json\n",
        "creds = json.loads(data)"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1738122481056
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.rag.utils.connections import get_connection_by_name_v2, create_connection_v2\n",
        "\n",
        "# # Define the connection name for Azure OpenAI\n",
        "aoai_connection_name = \"Custom_AzureOpenAI_Connection\"\n",
        "endpoint = creds.get(\"endpoint\", \"https://azureai202501.openai.azure.com/\")  # Use a default or handle missing key\n",
        "api_key = creds.get(\"key\", \"BispoQ9bDuajs4NvQV6hLb6trvEMh4MdpqtBclvImgiiCkHF4bBnJQQJ99BAACYeBjFXJ3w3AAABACOG99SW\")  # Use a default or handle missing key\n",
        "api_version = creds.get(\"api_version\", \"2024-05-01-preview\")  # Use a default or handle missing key\n",
        "\n",
        "# Create the Azure OpenAI connection\n",
        "aoai_connection = create_connection_v2(\n",
        "    workspace=ws,\n",
        "    name=aoai_connection_name,\n",
        "    category=\"AzureOpenAI\",\n",
        "    target=endpoint,\n",
        "    auth_type=\"ApiKey\",\n",
        "    credentials={\"key\": api_key},\n",
        "    metadata={\"ApiType\": \"azure\", \"ApiVersion\": \"2024-05-01-preview\"},\n",
        ")\n",
        "\n",
        "aoai_connection_id = aoai_connection[\"id\"]\n",
        "\n",
        "print(f\"Azure OpenAI connection created or retrieved successfully: {aoai_connection_id}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Azure OpenAI connection created or retrieved successfully: /subscriptions/b113073a-8845-458d-8462-4792938c8faa/resourceGroups/default_resorce_group/providers/Microsoft.MachineLearningServices/workspaces/pizzasalesworkspace/connections/Custom_AzureOpenAI_Connection\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1738122502530
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.rag.utils.deployment import infer_deployment\n",
        "\n",
        "pythonCopyEditaoai_embedding_model_name = creds.get(\"AZURE_OPENAI_EMBEDDING_MODEL\", \"gpt-4o-mini\")\n",
        "aoai_embedding_deployment_name = creds.get(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\", \"gpt-4o-mini\")\n",
        "embeddings_model_uri = f\"azure_open_ai://deployment/{aoai_embedding_deployment_name}/model/{pythonCopyEditaoai_embedding_model_name}\"\n",
        "print(f\"Embedding Model URI: {embeddings_model_uri}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Embedding Model URI: azure_open_ai://deployment/gpt-4o-mini/model/gpt-4o-mini\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1738122540268
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "#### HuggingFace\n"
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## **5. Setup Pipeline to process data into Index**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Define Pipeline Components**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Write you are code here\n",
        "# Import the MLClient to access the AzureML registry\n",
        "ml_registry = MLClient(credential=credential, registry_name=\"azureml\")\n",
        "\n",
        "# Retrieve components for processing data, generating embeddings, and creating the FAISS index\n",
        "crack_and_chunk_component = ml_registry.components.get(\n",
        "    \"llm_rag_crack_and_chunk\", label=\"latest\"\n",
        ")\n",
        "generate_embeddings_component = ml_registry.components.get(\n",
        "    \"llm_rag_generate_embeddings\", label=\"latest\"\n",
        ")\n",
        "create_faiss_index_component = ml_registry.components.get(\n",
        "    \"llm_rag_create_faiss_index\", label=\"latest\"\n",
        ")\n",
        "register_mlindex_component = ml_registry.components.get(\n",
        "    \"llm_rag_register_mlindex_asset\", label=\"latest\"\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Overriding of current TracerProvider is not allowed\nOverriding of current LoggerProvider is not allowed\nOverriding of current MeterProvider is not allowed\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1738122547595
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(crack_and_chunk_component)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\nname: llm_rag_crack_and_chunk\nversion: 0.0.78\ndisplay_name: LLM - Crack and Chunk Data\ndescription: 'Creates chunks no larger than `chunk_size` from `input_data`, extracted\n  document titles are prepended to each chunk\n\n\n  LLM models have token limits for the prompts passed to them, this is a limiting\n  factor at embedding time and even more limiting at prompt completion time as only\n  so much context can be passed along with instructions to the LLM and user queries.\n\n  Chunking allows splitting source data of various formats into small but coherent\n  snippets of information which can be ''packed'' into LLM prompts when asking for\n  answers to user query related to the source documents.\n\n\n  Supported formats: md, txt, html/htm, pdf, ppt(x), doc(x), xls(x), py\n\n  '\ntags:\n  Preview: ''\ntype: command\ninputs:\n  input_data:\n    type: uri_folder\n    description: Uri Folder containing files to be chunked.\n    optional: false\n  input_glob:\n    type: string\n    optional: true\n    description: Limit files opened from `input_data`, defaults to '**/*'.\n  allowed_extensions:\n    type: string\n    optional: true\n    description: Comma separated list of extensions to include, if not provided the\n      default list of supported extensions will be used. e.g. '.md,.txt,.html,.py,.pdf.'\n  chunk_size:\n    type: integer\n    optional: false\n    default: '768'\n    description: Maximum number of tokens to put in each chunk.\n  chunk_overlap:\n    type: integer\n    optional: false\n    default: '0'\n    description: Number of tokens to overlap between chunks.\n  doc_intel_connection_id:\n    type: string\n    optional: true\n    description: Connection id for Document Intelligence service. If provided, will\n      be used to extract content from .pdf document.\n  data_source_url:\n    type: string\n    optional: true\n    description: Base URL to join with file paths to create full source file URL for\n      chunk metadata.\n  document_path_replacement_regex:\n    type: string\n    optional: true\n    description: 'A JSON string with two fields, ''match_pattern'' and ''replacement_pattern''\n      to be used with re.sub on the source url. e.g. ''{\"match_pattern\": \"(.*)/articles/(.*)(\\\\.[^.]+)$\",\n      \"replacement_pattern\": \"\\\\1/\\\\2\"}'' would remove ''/articles'' from the middle\n      of the url.'\n  max_sample_files:\n    type: integer\n    optional: false\n    default: '-1'\n    description: Number of files to chunk. Specify -1 to chunk all documents in input\n      path.\n  use_rcts:\n    type: string\n    optional: false\n    default: 'True'\n    description: Whether to use RecursiveCharacterTextSplitter to split documents\n      into chunks\n    enum:\n    - 'True'\n    - 'False'\n  output_format:\n    type: string\n    optional: false\n    default: jsonl\n    description: Format of the output chunk file\n    enum:\n    - csv\n    - jsonl\noutputs:\n  output_chunks:\n    type: uri_folder\n    description: Uri Folder containing chunks. Each chunk will be a separate file\n      in the folder\ncommand: python -m azureml.rag.tasks.crack_and_chunk --input_data '${{inputs.input_data}}'\n  $[[--input_glob '${{inputs.input_glob}}']] $[[--allowed_extensions ${{inputs.allowed_extensions}}]]\n  --output_chunks ${{outputs.output_chunks}} --chunk_size ${{inputs.chunk_size}} --chunk_overlap\n  ${{inputs.chunk_overlap}} $[[--doc_intel_connection_id ${{inputs.doc_intel_connection_id}}]]\n  $[[--data_source_url ${{inputs.data_source_url}}]] $[[--document_path_replacement_regex\n  '${{inputs.document_path_replacement_regex}}']] --max_sample_files ${{inputs.max_sample_files}}\n  --use_rcts '${{inputs.use_rcts}}' --output_format ${{inputs.output_format}}\nenvironment: azureml://registries/azureml/environments/llm-rag-embeddings/versions/76\ncode: azureml://registries/azureml/codes/2062c1ba-8a97-4ea3-acc3-a7b2e5f8fa58/versions/1\nresources:\n  instance_count: 1\ncreation_context:\n  created_at: '2025-01-02T05:48:55.228512+00:00'\n  created_by: Microsoft\n  created_by_type: User\n  last_modified_at: '2025-01-02T05:48:55.228512+00:00'\n  last_modified_by: Microsoft\n  last_modified_by_type: User\nid: azureml://registries/azureml/components/llm_rag_crack_and_chunk/versions/0.0.78\nis_deterministic: true\n\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1738122552341
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Build the AzureML Pipeline**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Write you are code here\n",
        "from azure.ai.ml import Input, Output\n",
        "from azure.ai.ml.dsl import pipeline\n",
        "from azure.ai.ml.entities._job.pipeline._io import PipelineInput\n",
        "from typing import Optional"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1738122556255
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility function for automatic compute configuration\n",
        "def use_automatic_compute(component, instance_count=1, instance_type=\"Standard_NC4as_T4_v3\"):\n",
        "    \"\"\"Configure a component to use automatic compute.\"\"\"\n",
        "    component.set_resources(\n",
        "        instance_count=instance_count,\n",
        "        instance_type=instance_type,\n",
        "        properties={\"compute_specification\": {\"automatic\": True}},\n",
        "    )\n",
        "    return component\n",
        "\n",
        "\n",
        "# Utility function to check if optional pipeline inputs are provided\n",
        "def optional_pipeline_input_provided(input: Optional[PipelineInput]):\n",
        "    \"\"\"Check if optional pipeline inputs are provided.\"\"\"\n",
        "    return input is not None and input._data is not None"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1738122560407
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@pipeline(default_compute=\"serverless\")   #Fill the blank with name of the pipeline and compute\n",
        "def diagnosismanuals_to_faiss(\n",
        "    data_asset_path: str,\n",
        "    embeddings_model: str,\n",
        "    asset_name: str,\n",
        "    chunk_size: int = 1024,    #Provide the chink size \n",
        "    data_source_glob: str = None,\n",
        "    document_path_replacement_regex: str = None,\n",
        "    aoai_connection_id=None,\n",
        "    embeddings_container=None,\n",
        "):\n",
        "    \"\"\"Pipeline to process medical diagnosis manuals and create a FAISS vector index for knowledge retrieval.\"\"\"\n",
        "    \n",
        "    # Step 1: Chunk data into smaller pieces\n",
        "    crack_and_chunk = crack_and_chunk_component(\n",
        "        input_data=Input(type=\"uri_folder\", path=data_asset_path),  # Input data asset and fill the blank with proper type \n",
        "        input_glob=data_source_glob,\n",
        "        chunk_size=chunk_size,\n",
        "        document_path_replacement_regex=document_path_replacement_regex,\n",
        "    )\n",
        "    use_automatic_compute(crack_and_chunk)  # Apply compute configuration\n",
        "\n",
        "    # Step 2: Generate embeddings for the data chunks\n",
        "    generate_embeddings = generate_embeddings_component(\n",
        "        chunks_source=crack_and_chunk.outputs.output_chunks,\n",
        "        embeddings_container=embeddings_container,\n",
        "        embeddings_model=embeddings_model,\n",
        "    )\n",
        "    use_automatic_compute(generate_embeddings)  # Apply compute configuration\n",
        "    \n",
        "    # Optional: Include Azure OpenAI connection ID\n",
        "    #if optional_pipeline_input_provided(aoai_connection_id):\n",
        "    #    generate_embeddings.environment_variables[                        #Fill the blank with proper variable\n",
        "    #        \"AZUREML_WORKSPACE_CONNECTION_ID_AOAI\"\n",
        "    #    ] = aoai_connection_id\n",
        "    #if optional_pipeline_input_provided(embeddings_container):\n",
        "    #   generate_embeddings.outputs.embeddings = Output(\n",
        "    #        type=\"uri_folder\", path=f\"{embeddings_container.path}/{{name}}\"    #Fill the blank with proper type\n",
        "    #    )\n",
        "\n",
        "    # Step 3: Create a FAISS vector index from embeddings\n",
        "    create_faiss_index = create_faiss_index_component(\n",
        "        embeddings=generate_embeddings.outputs.embeddings,    #Fill the balnk with proper function\n",
        "    )\n",
        "    use_automatic_compute(create_faiss_index)  # Apply compute configuration\n",
        "\n",
        "    # Step 4: Register the FAISS index as an MLIndex asset\n",
        "    register_mlindex = register_mlindex_component(\n",
        "        storage_uri=create_faiss_index.outputs.index,    #Fill the balnk with proper function\n",
        "        asset_name=asset_name\n",
        "    )\n",
        "    use_automatic_compute(register_mlindex) # Apply compute configuration\n",
        "    \n",
        "    return {\n",
        "        \"mlindex_asset_uri\": create_faiss_index.outputs.index,\n",
        "        \"mlindex_asset_id\": register_mlindex.outputs.asset_id,\n",
        "    }"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1738122575294
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6.Submit the Pipeline**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the asset name and data source glob pattern\n",
        "asset_name = \"Medical-Diagnosis-list\"  # Name for the FAISS index asset\n",
        "data_source_glob = \"**/*.pdf\"  # Pattern to match input data files"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1738122579540
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the input data asset path from the workspace datastore\n",
        "datastore_path = ml_client.data.get(data_asset_name, version=\"7\").path\n",
        "print(f\"Datastore path: {datastore_path}\")\n",
        "print(f\"assest name: {asset_name}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Datastore path: azureml://subscriptions/b113073a-8845-458d-8462-4792938c8faa/resourcegroups/default_resorce_group/workspaces/pizzasalesworkspace/datastores/workspaceblobstore/paths/LocalUpload/a0c35917db9eab5fa2442a9597890dcf/MedicalDiagnosisManual/\nassest name: Medical-Diagnosis-list\n"
        }
      ],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1738122582338
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#azureml://subscriptions/b113073a-8845-458d-8462-4792938c8faa/resourcegroups/default_resorce_group/workspaces/pizzasalesworkspace/datastores/workspaceblobstore/paths/LocalUpload/a0c35917db9eab5fa2442a9597890dcf/MedicalDiagnosisManual/"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1738122597335
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"model uri: {embeddings_model_uri}\")\n",
        "\n",
        "print(f\"{asset_name}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "model uri: azure_open_ai://deployment/gpt-4o-mini/model/gpt-4o-mini\nMedical-Diagnosis-list\n"
        }
      ],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1738122599296
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the pipeline job by calling the defined pipeline function\n",
        "pipeline_job = diagnosismanuals_to_faiss(\n",
        "    embeddings_model=embeddings_model_uri,  # URI of the embeddings model\n",
        "    #aoai_connection_id=aoai_connection_id,  # Connection ID for Azure OpenAI (optional)\n",
        "    embeddings_container=Input(\n",
        "        type=\"uri_folder\",\n",
        "        path=f\"azureml://datastores/workspaceblobstore/paths/embeddings/{asset_name}\"    \n",
        "    ),  # Path for storing generated embeddings\n",
        "    data_asset_path=Input(\n",
        "        type=\"uri_folder\",\n",
        "        path=datastore_path\n",
        "    ),  # Input data asset path\n",
        "    chunk_size=1024,  # Size of chunks for processing\n",
        "    data_source_glob=data_source_glob,  # Glob pattern for input files\n",
        "    asset_name=asset_name  # Name of the MLIndex asset\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1738122602899
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add properties for better indexing and artifact tracking in the AzureML UI\n",
        "pipeline_job.properties[\"azureml.mlIndexAssetName\"] = asset_name\n",
        "pipeline_job.properties[\"azureml.mlIndexAssetKind\"] = \"faiss\"\n",
        "pipeline_job.properties[\"azureml.mlIndexAssetSource\"] = \"Data asset\""
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1738122612330
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit the pipeline job for execution\n",
        "submitted_pipeline = ml_client.jobs.create_or_update(pipeline_job)\n",
        "print(f\"Pipeline submitted successfully! Job ID: {submitted_pipeline.id}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\npathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\npathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFileJobOutput'> and will be ignored\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Pipeline submitted successfully! Job ID: /subscriptions/b113073a-8845-458d-8462-4792938c8faa/resourceGroups/default_resorce_group/providers/Microsoft.MachineLearningServices/workspaces/pizzasalesworkspace/jobs/cool_whistle_v6mmhp8qnx\n"
        }
      ],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1738122618089
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stream the pipeline job logs for real-time monitoring\n",
        "ml_client.jobs.stream(submitted_pipeline.name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "RunId: cool_whistle_v6mmhp8qnx\nWeb View: https://ml.azure.com/runs/cool_whistle_v6mmhp8qnx?wsid=/subscriptions/b113073a-8845-458d-8462-4792938c8faa/resourcegroups/default_resorce_group/workspaces/pizzasalesworkspace\n\nStreaming logs/azureml/executionlogs.txt\n========================================\n\n[2025-01-29 03:50:22Z] Completing processing run id 5b03fb75-551c-4bef-84bd-da2e1d22e3cd.\n[2025-01-29 03:50:23Z] Submitting 1 runs, first five are: 8d05f3f7:d138ab8e-8d87-45fd-afd2-b22c9819863e\n[2025-01-29 03:58:58Z] Execution of experiment failed, update experiment status and cancel running nodes.\n\nExecution Summary\n=================\nRunId: cool_whistle_v6mmhp8qnx\nWeb View: https://ml.azure.com/runs/cool_whistle_v6mmhp8qnx?wsid=/subscriptions/b113073a-8845-458d-8462-4792938c8faa/resourcegroups/default_resorce_group/workspaces/pizzasalesworkspace\n"
        },
        {
          "output_type": "error",
          "ename": "JobException",
          "evalue": "Exception : \n {\n    \"error\": {\n        \"code\": \"ServiceError\",\n        \"message\": \"Pipeline has failed child jobs. Failed nodes: /generate_embeddings. For more details and logs, please go to the job detail page and check the child jobs.\",\n        \"message_format\": \"Pipeline has failed child jobs. {0}\",\n        \"message_parameters\": {},\n        \"reference_code\": \"PipelineHasStepJobFailed\",\n        \"details\": []\n    },\n    \"environment\": \"eastus\",\n    \"location\": \"eastus\",\n    \"time\": \"2025-01-29T03:58:58.294519Z\",\n    \"component_name\": \"\"\n} ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJobException\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Stream the pipeline job logs for real-time monitoring\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mml_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjobs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubmitted_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/azure/core/tracing/decorator.py:105\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m tracing_attributes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    104\u001b[0m     span\u001b[38;5;241m.\u001b[39madd_attribute(key, value)\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/azure/ai/ml/_telemetry/activity.py:288\u001b[0m, in \u001b[0;36mmonitor_with_activity.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tracer\u001b[38;5;241m.\u001b[39mstart_as_current_span(ACTIVITY_SPAN):\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m log_activity(\n\u001b[1;32m    286\u001b[0m             logger\u001b[38;5;241m.\u001b[39mpackage_logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions\n\u001b[1;32m    287\u001b[0m         ):\n\u001b[0;32m--> 288\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(logger, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpackage_logger\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m log_activity(logger\u001b[38;5;241m.\u001b[39mpackage_logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions):\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/azure/ai/ml/operations/_job_operations.py:844\u001b[0m, in \u001b[0;36mJobOperations.stream\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_pipeline_child_job(job_object):\n\u001b[1;32m    842\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PipelineChildJobError(job_id\u001b[38;5;241m=\u001b[39mjob_object\u001b[38;5;241m.\u001b[39mid)\n\u001b[0;32m--> 844\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream_logs_until_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_runs_operations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_datastore_operations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequests_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_requests_pipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/azure/ai/ml/operations/_job_ops_helper.py:334\u001b[0m, in \u001b[0;36mstream_logs_until_completion\u001b[0;34m(run_operations, job_resource, datastore_operations, raise_exception_on_failed_job, requests_pipeline)\u001b[0m\n\u001b[1;32m    332\u001b[0m         file_handle\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 334\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m JobException(\n\u001b[1;32m    335\u001b[0m             message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException : \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(json\u001b[38;5;241m.\u001b[39mdumps(error, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)),\n\u001b[1;32m    336\u001b[0m             target\u001b[38;5;241m=\u001b[39mErrorTarget\u001b[38;5;241m.\u001b[39mJOB,\n\u001b[1;32m    337\u001b[0m             no_personal_data_message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException raised on failed job.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    338\u001b[0m             error_category\u001b[38;5;241m=\u001b[39mErrorCategory\u001b[38;5;241m.\u001b[39mSYSTEM_ERROR,\n\u001b[1;32m    339\u001b[0m         )\n\u001b[1;32m    341\u001b[0m file_handle\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    342\u001b[0m file_handle\u001b[38;5;241m.\u001b[39mflush()\n",
            "\u001b[0;31mJobException\u001b[0m: Exception : \n {\n    \"error\": {\n        \"code\": \"ServiceError\",\n        \"message\": \"Pipeline has failed child jobs. Failed nodes: /generate_embeddings. For more details and logs, please go to the job detail page and check the child jobs.\",\n        \"message_format\": \"Pipeline has failed child jobs. {0}\",\n        \"message_parameters\": {},\n        \"reference_code\": \"PipelineHasStepJobFailed\",\n        \"details\": []\n    },\n    \"environment\": \"eastus\",\n    \"location\": \"eastus\",\n    \"time\": \"2025-01-29T03:58:58.294519Z\",\n    \"component_name\": \"\"\n} "
          ]
        }
      ],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1738123192123
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Information Retrieval and Response Generation Using LangChain-FAISS and Azure OpenAI**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.Installing Required Libraries**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the required LangChain and HuggingFace libraries\n",
        "%pip install -U langchain-community\n",
        "%pip install -U langchain-huggingface\n",
        "%pip install -U langchain-openai"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting langchain-community\n  Downloading langchain_community-0.3.16-py3-none-any.whl (2.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting langsmith<0.4,>=0.1.125\n  Downloading langsmith-0.3.2-py3-none-any.whl (333 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m333.0/333.0 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-community) (3.10.1)\nCollecting SQLAlchemy<3,>=1.4\n  Downloading SQLAlchemy-2.0.37-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy<2,>=1.22.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-community) (1.23.5)\nRequirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-community) (2.4.0)\nCollecting langchain-core<0.4.0,>=0.3.32\n  Downloading langchain_core-0.3.32-py3-none-any.whl (412 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.4/412.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting dataclasses-json<0.7,>=0.5.7\n  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-community) (9.0.0)\nRequirement already satisfied: requests<3,>=2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-community) (2.32.3)\nRequirement already satisfied: PyYAML>=5.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-community) (6.0.1)\nCollecting httpx-sse<0.5.0,>=0.4.0\n  Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\nCollecting langchain<0.4.0,>=0.3.16\n  Downloading langchain-0.3.16-py3-none-any.whl (1.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: yarl<2.0,>=1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.3.5)\nRequirement already satisfied: attrs>=17.3.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\nRequirement already satisfied: multidict<7.0,>=4.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.0)\nCollecting typing-inspect<1,>=0.4.0\n  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\nCollecting langchain-text-splitters<0.4.0,>=0.3.3\n  Downloading langchain_text_splitters-0.3.5-py3-none-any.whl (31 kB)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.16->langchain-community) (2.9.2)\nRequirement already satisfied: packaging<25,>=23.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.32->langchain-community) (24.1)\nCollecting jsonpatch<2.0,>=1.33\n  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\nRequirement already satisfied: typing-extensions>=4.7 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.32->langchain-community) (4.12.2)\nCollecting requests-toolbelt<2.0.0,>=1.0.0\n  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting zstandard<0.24.0,>=0.23.0\n  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: httpx<1,>=0.23.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.27.2)\nCollecting orjson<4.0.0,>=3.9.14\n  Downloading orjson-3.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.3/130.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: python-dotenv>=0.21.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (1.26.19)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (2024.8.30)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.7)\nRequirement already satisfied: greenlet!=0.4.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\nRequirement already satisfied: sniffio in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\nRequirement already satisfied: httpcore==1.* in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.5)\nRequirement already satisfied: anyio in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.6.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.32->langchain-community) (3.0.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.16->langchain-community) (2.23.4)\nRequirement already satisfied: annotated-types>=0.6.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.16->langchain-community) (0.7.0)\nCollecting mypy-extensions>=0.3.0\n  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.2.2)\nInstalling collected packages: zstandard, SQLAlchemy, orjson, mypy-extensions, jsonpatch, httpx-sse, typing-inspect, requests-toolbelt, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain, langchain-community\nSuccessfully installed SQLAlchemy-2.0.37 dataclasses-json-0.6.7 httpx-sse-0.4.0 jsonpatch-1.33 langchain-0.3.16 langchain-community-0.3.16 langchain-core-0.3.32 langchain-text-splitters-0.3.5 langsmith-0.3.2 mypy-extensions-1.0.0 orjson-3.10.15 requests-toolbelt-1.0.0 typing-inspect-0.9.0 zstandard-0.23.0\nNote: you may need to restart the kernel to use updated packages.\nCollecting langchain-huggingface\n  Downloading langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\nCollecting sentence-transformers>=2.6.0\n  Downloading sentence_transformers-3.4.0-py3-none-any.whl (275 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting transformers>=4.39.0\n  Downloading transformers-4.48.1-py3-none-any.whl (9.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting tokenizers>=0.19.1\n  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: huggingface-hub>=0.23.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-huggingface) (0.24.5)\nRequirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-huggingface) (0.3.32)\nRequirement already satisfied: filelock in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.15.4)\nRequirement already satisfied: pyyaml>=5.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (6.0.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2023.10.0)\nRequirement already satisfied: packaging>=20.9 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (24.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.12.2)\nRequirement already satisfied: tqdm>=4.42.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.66.4)\nRequirement already satisfied: requests in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2.32.3)\nRequirement already satisfied: langsmith<0.4,>=0.1.125 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.3.2)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (9.0.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.33)\nRequirement already satisfied: pydantic<3.0.0,>=2.5.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.9.2)\nRequirement already satisfied: scikit-learn in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.5.1)\nRequirement already satisfied: scipy in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.10.1)\nRequirement already satisfied: torch>=1.11.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.4.1)\nRequirement already satisfied: Pillow in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (9.2.0)\nRequirement already satisfied: regex!=2019.12.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from transformers>=4.39.0->langchain-huggingface) (2024.7.24)\nRequirement already satisfied: numpy>=1.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from transformers>=4.39.0->langchain-huggingface) (1.23.5)\nRequirement already satisfied: safetensors>=0.4.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from transformers>=4.39.0->langchain-huggingface) (0.4.4)\nRequirement already satisfied: jsonpointer>=1.9 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.0.0)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.10.15)\nRequirement already satisfied: httpx<1,>=0.23.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.27.2)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.23.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.23.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.3.2)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2024.8.30)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (1.26.19)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.1.0.106)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.1.105)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.1.105)\nRequirement already satisfied: triton==3.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.0.0)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (11.0.2.54)\nRequirement already satisfied: sympy in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\nRequirement already satisfied: jinja2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.4)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (9.1.0.70)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.20.5)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.1.3.1)\nRequirement already satisfied: networkx in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.1.105)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.6.68)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.5.0)\nRequirement already satisfied: joblib>=1.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.2.0)\nRequirement already satisfied: anyio in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (4.6.0)\nRequirement already satisfied: httpcore==1.* in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.5)\nRequirement already satisfied: sniffio in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.14.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.2.2)\nInstalling collected packages: tokenizers, transformers, sentence-transformers, langchain-huggingface\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.15.2\n    Uninstalling tokenizers-0.15.2:\n      Successfully uninstalled tokenizers-0.15.2\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.36.2\n    Uninstalling transformers-4.36.2:\n      Successfully uninstalled transformers-4.36.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nazureml-automl-dnn-nlp 1.57.0 requires torch==1.13.1, but you have torch 2.4.1 which is incompatible.\nazureml-automl-dnn-nlp 1.57.0 requires transformers[sentencepiece,torch]<=4.36.2, but you have transformers 4.48.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed langchain-huggingface-0.1.2 sentence-transformers-3.4.0 tokenizers-0.21.0 transformers-4.48.1\nNote: you may need to restart the kernel to use updated packages.\nCollecting langchain-openai\n  Downloading langchain_openai-0.3.2-py3-none-any.whl (54 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: openai<2.0.0,>=1.58.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-openai) (1.60.2)\nRequirement already satisfied: langchain-core<0.4.0,>=0.3.31 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-openai) (0.3.32)\nRequirement already satisfied: tiktoken<1,>=0.7 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-openai) (0.8.0)\nRequirement already satisfied: PyYAML>=5.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.31->langchain-openai) (6.0.1)\nRequirement already satisfied: typing-extensions>=4.7 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.31->langchain-openai) (4.12.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.31->langchain-openai) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.31->langchain-openai) (24.1)\nRequirement already satisfied: pydantic<3.0.0,>=2.5.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.31->langchain-openai) (2.9.2)\nRequirement already satisfied: langsmith<0.4,>=0.1.125 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.31->langchain-openai) (0.3.2)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.31->langchain-openai) (9.0.0)\nRequirement already satisfied: tqdm>4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.66.4)\nRequirement already satisfied: jiter<1,>=0.4.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\nRequirement already satisfied: distro<2,>=1.7.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.27.2)\nRequirement already satisfied: sniffio in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\nRequirement already satisfied: anyio<5,>=3.5.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.6.0)\nRequirement already satisfied: requests>=2.26.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\nRequirement already satisfied: regex>=2022.1.18 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.7.24)\nRequirement already satisfied: idna>=2.8 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai) (3.7)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai) (1.2.2)\nRequirement already satisfied: certifi in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (2024.8.30)\nRequirement already satisfied: httpcore==1.* in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.31->langchain-openai) (3.0.0)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.31->langchain-openai) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.31->langchain-openai) (0.23.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.31->langchain-openai) (3.10.15)\nRequirement already satisfied: pydantic-core==2.23.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.31->langchain-openai) (2.23.4)\nRequirement already satisfied: annotated-types>=0.6.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.31->langchain-openai) (0.7.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (1.26.19)\nInstalling collected packages: langchain-openai\nSuccessfully installed langchain-openai-0.3.2\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1738123957317
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Setting Up Data Retrieval**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Downloading and Setting Up FAISS Index Assets**\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary utilities for artifact retrieval\n",
        "import azure.ai.ml._artifacts._artifact_utilities as artifact_utils\n",
        "\n",
        "# Retrieve the path to the latest FAISS index asset from Azure ML\n",
        "data_info = ml_client.data.get(name=asset_name, label=\"latest\").path\n",
        "\n",
        "# Download the FAISS index asset to a local directory\n",
        "artifact_utils.download_artifact_from_aml_uri(\n",
        "    uri=data_info,\n",
        "    destination=\"./medicaldiagnosisfaissindexasset/\",\n",
        "    datastore_operation=ml_client.datastores\n",
        ")\n",
        "\n",
        "# The FAISS index asset will be used for vector-based similarity search."
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 29,
          "data": {
            "text/plain": "'./medicaldiagnosisfaissindexasset/'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1738124000157
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Loading the FAISS Index**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Loading the FAISS Index and Preparing the Retriever**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the directory containing FAISS index files\n",
        "index_folder_path = \"./medicaldiagnosisfaissindexasset/\""
      ],
      "outputs": [],
      "execution_count": 30,
      "metadata": {
        "gather": {
          "logged": 1738124009466
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "creds = {\n",
        "    \"AZURE_OPENAI_EMBEDDING_MODEL\": \"gpt-4o-mini\",  # Replace with your actual model name\n",
        "    \"AZURE_OPENAI_ENDPOINT\": \"https://azureai202501.openai.azure.com/\",\n",
        "    \"AZURE_OPENAI_KY\": \"BispoQ9bDuajs4NvQV6hLb6trvEMh4MdpqtBclvImgiiCkHF4bBnJQQJ99BAACYeBjFXJ3w3AAABACOG99SW\",  # Replace with your actual API key\n",
        "    \"AZURE_OPENAI_APIVERSION\": \"2024-05-01-preview\"  # Replace with the correct API version\n",
        "}"
      ],
      "outputs": [],
      "execution_count": 31,
      "metadata": {
        "gather": {
          "logged": 1738124012738
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import AzureOpenAIEmbeddings\n",
        "\n",
        "# Initialize the embedding model with the provided credentials\n",
        "embedding_model = AzureOpenAIEmbeddings(\n",
        "    model=creds[\"AZURE_OPENAI_EMBEDDING_MODEL\"],\n",
        "    azure_endpoint=creds[\"AZURE_OPENAI_ENDPOINT\"],\n",
        "    api_key=creds[\"AZURE_OPENAI_KY\"],\n",
        "    openai_api_version=creds[\"AZURE_OPENAI_APIVERSION\"]\n",
        ")\n",
        "print(f\"embeddings model: {embedding_model}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "embeddings model: client=<openai.resources.embeddings.Embeddings object at 0x7fb1204241f0> async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x7fb11d0ffb20> model='gpt-4o-mini' dimensions=None deployment=None openai_api_version='2024-05-01-preview' openai_api_base=None openai_api_type='azure' openai_proxy=None embedding_ctx_length=8191 openai_api_key=SecretStr('**********') openai_organization=None allowed_special=None disallowed_special=None chunk_size=2048 max_retries=2 request_timeout=None headers=None tiktoken_enabled=True tiktoken_model_name=None show_progress_bar=False model_kwargs={} skip_empty=False default_headers=None default_query=None retry_min_seconds=4 retry_max_seconds=20 http_client=None http_async_client=None check_embedding_ctx_length=True azure_endpoint='https://azureai202501.openai.azure.com/' azure_ad_token=None azure_ad_token_provider=None azure_ad_async_token_provider=None validate_base_url=True\n"
        }
      ],
      "execution_count": 32,
      "metadata": {
        "gather": {
          "logged": 1738124023191
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "# Load the FAISS index and associate it with the embedding model\n",
        "retriever = FAISS.load_local(\n",
        "    folder_path=index_folder_path, \n",
        "    embeddings=embedding_model, \n",
        "    allow_dangerous_deserialization=True  # Acknowledge the source of the data for safe loading\n",
        ")\n",
        "\n",
        "# The retriever is now ready to perform similarity searches."
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error in faiss::FileIOReader::FileIOReader(const char*) at /project/faiss/faiss/impl/io.cpp:67: Error: 'f' failed: could not open medicaldiagnosisfaissindexasset/index.faiss for reading: No such file or directory",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_3336/402736373.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorstores\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFAISS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the FAISS index and associate it with the embedding model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m retriever = FAISS.load_local(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mfolder_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_folder_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0membeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mallow_dangerous_deserialization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m  \u001b[0;31m# Acknowledge the source of the data for safe loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/langchain_community/vectorstores/faiss.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(cls, folder_path, embeddings, index_name, allow_dangerous_deserialization, **kwargs)\u001b[0m\n\u001b[1;32m   1201\u001b[0m             )\n\u001b[1;32m   1202\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m         \u001b[0;31m# load index separately since it is not picklable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m         \u001b[0mfaiss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdependable_faiss_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1205\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfaiss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34mf\"{index_name}.faiss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m         \u001b[0;31m# load docstore and index_to_docstore_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34mf\"{index_name}.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/faiss/swigfaiss_avx2.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m  10205\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10206\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_swigfaiss_avx2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Error in faiss::FileIOReader::FileIOReader(const char*) at /project/faiss/faiss/impl/io.cpp:67: Error: 'f' failed: could not open medicaldiagnosisfaissindexasset/index.faiss for reading: No such file or directory"
          ]
        }
      ],
      "execution_count": 33,
      "metadata": {
        "gather": {
          "logged": 1738124031113
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"FAISS index saved at {index_folder_path}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "FAISS index saved at ./medicaldiagnosisfaissindexasset/\n"
        }
      ],
      "execution_count": 95,
      "metadata": {
        "gather": {
          "logged": 1737872613347
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Performing a Similarity Search**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a query to test the retriever - you can feel free to pick any disease or medical condition for this \n",
        "\n",
        "query = \"What are the common symptoms and treatments for pulmonary embolism?\"\n",
        "\n",
        "# Retrieve the top 3 most relevant documents\n",
        "results = retriever.similarity_search(query, k=3)\n",
        "\n",
        "# Display the results\n",
        "for doc in results:\n",
        "    print(f\"Document: {doc.page_content}\\nMetadata: {doc.metadata}\")\n",
        "\n",
        "# This step helps validate that the retriever is functioning as expected."
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'retriever' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[96], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat are the common symptoms and treatments for pulmonary embolism?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Retrieve the top 3 most relevant documents\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241m.\u001b[39msimilarity_search(query, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Display the results\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m results:\n",
            "\u001b[0;31mNameError\u001b[0m: name 'retriever' is not defined"
          ]
        }
      ],
      "execution_count": 96,
      "metadata": {
        "gather": {
          "logged": 1737872619304
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5: Creating the System and User Prompt Templates**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the system prompt for the Azure OpenAI model\n",
        "qna_system_message = \"\"\"\n",
        "    #Write you are message here\n",
        "\"\"\"\n",
        "# Define the user message template\n",
        "qna_user_message_template = \"\"\"\n",
        "###Context\n",
        "Here are some documents that are relevant to the question mentioned below.\n",
        "{context}\n",
        "\n",
        "###Question\n",
        "{question}\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 97,
      "metadata": {
        "gather": {
          "logged": 1737872625342
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6. Generating the Response**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the rquired packages\n",
        "%pip install openai==1.2.0 tiktoken==0.6 session-info --quiet"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndask-sql 2024.5.0 requires dask[dataframe]>=2024.4.1, but you have dask 2023.2.0 which is incompatible.\ndask-sql 2024.5.0 requires distributed>=2024.4.1, but you have distributed 2023.2.0 which is incompatible.\ndask-sql 2024.5.0 requires pandas>=1.4.0, but you have pandas 1.3.5 which is incompatible.\nazureml-rag 0.2.37.2 requires tiktoken<0.6, but you have tiktoken 0.6.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 46,
      "metadata": {
        "gather": {
          "logged": 1737179365472
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import json\n",
        "import tiktoken\n",
        "import pandas as pd\n",
        "from openai import AzureOpenAI"
      ],
      "outputs": [],
      "execution_count": 98,
      "metadata": {
        "gather": {
          "logged": 1737872639490
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Azure OpenAI credentials\n",
        "with open('config.json', 'r') as az_creds:\n",
        "    data = az_creds.read()\n",
        "\n",
        "creds = json.loads(data)\n",
        "\n",
        "#print(creds)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'config.json'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[100], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load Azure OpenAI credentials\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconfig.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m az_creds:\n\u001b[1;32m      3\u001b[0m     data \u001b[38;5;241m=\u001b[39m az_creds\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m      5\u001b[0m creds \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(data)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'config.json'"
          ]
        }
      ],
      "execution_count": 100,
      "metadata": {
        "gather": {
          "logged": 1737872712100
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#endpoint = creds.get(\"endpoint\", \"https://azureai2025.openai.azure.com/\")  # Use a default or handle missing key\n",
        "#api_key = creds.get(\"key\", \"BispoQ9bDuajs4NvQV6hLb6trvEMh4MdpqtBclvImgiiCkHF4bBnJQQJ99BAACYeBjFXJ3w3AAABACOG99SW\")  # Use a default or handle missing key\n",
        "#api_version = creds.get(\"api_version\", \"2024-05-01-preview\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1737178038645
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Azure OpenAI client\n",
        "client = AzureOpenAI(\n",
        "    azure_endpoint=creds[\"endpoint\"],\n",
        "    api_key=creds[\"key\"],\n",
        "    api_version=creds[\"api_version\"]\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'endpoint'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[101], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize the Azure OpenAI client\u001b[39;00m\n\u001b[1;32m      2\u001b[0m client \u001b[38;5;241m=\u001b[39m AzureOpenAI(\n\u001b[0;32m----> 3\u001b[0m     azure_endpoint\u001b[38;5;241m=\u001b[39m\u001b[43mcreds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mendpoint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[1;32m      4\u001b[0m     api_key\u001b[38;5;241m=\u001b[39mcreds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      5\u001b[0m     api_version\u001b[38;5;241m=\u001b[39mcreds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_version\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      6\u001b[0m )\n",
            "\u001b[0;31mKeyError\u001b[0m: 'endpoint'"
          ]
        }
      ],
      "execution_count": 101,
      "metadata": {
        "gather": {
          "logged": 1737872724332
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_rag_response(user_input):\n",
        "    # Retrieve relevant document chunks\n",
        "    relevant_document_chunks = retriever.similarity_search(user_input, k=3)\n",
        "    context_list = [d.page_content for d in relevant_document_chunks]\n",
        "\n",
        "    # Combine document chunks into a single context\n",
        "    context_for_query = \". \".join(context_list)\n",
        "\n",
        "    # Compose the prompt\n",
        "    prompt = [\n",
        "        {'role': 'system', 'content': qna_system_message},\n",
        "        {'role': 'user', 'content': qna_user_message_template.format(\n",
        "            context=context_for_query,\n",
        "            question=user_input\n",
        "            )\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Generate the response using Azure OpenAI\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=creds[\"CHATGPT_MODEL\"],\n",
        "            messages=prompt,\n",
        "            temperature=0\n",
        "        )\n",
        "\n",
        "        # Extract and print the model's response\n",
        "        response = response.choices[0].message.content.strip()\n",
        "    except Exception as e:\n",
        "        response = f'Sorry, I encountered the following error: \\n {e}'\n",
        "\n",
        "\n",
        "    print(response)\n"
      ],
      "outputs": [],
      "execution_count": 102,
      "metadata": {
        "gather": {
          "logged": 1737872729363
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Question 1: What is the protocol for managing sepsis in a critical care unit?"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"What is the protocol for managing sepsis in a critical care unit?\"    # Enter the question to be answered by the system here \n",
        "generate_rag_response(user_input)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'retriever' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[103], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the protocol for managing sepsis in a critical care unit?\u001b[39m\u001b[38;5;124m\"\u001b[39m    \u001b[38;5;66;03m# Enter the question to be answered by the system here \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mgenerate_rag_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[102], line 3\u001b[0m, in \u001b[0;36mgenerate_rag_response\u001b[0;34m(user_input)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_rag_response\u001b[39m(user_input):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Retrieve relevant document chunks\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     relevant_document_chunks \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241m.\u001b[39msimilarity_search(user_input, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      4\u001b[0m     context_list \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m relevant_document_chunks]\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Combine document chunks into a single context\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'retriever' is not defined"
          ]
        }
      ],
      "execution_count": 103,
      "metadata": {
        "gather": {
          "logged": 1737872733906
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Question 2: What are the common symptoms for appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"What are the common symptoms for appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?\"   # Enter the question to be answered by the system here \n",
        "generate_rag_response(user_input)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'retriever' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[104], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat are the common symptoms for appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?\u001b[39m\u001b[38;5;124m\"\u001b[39m   \u001b[38;5;66;03m# Enter the question to be answered by the system here \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mgenerate_rag_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[102], line 3\u001b[0m, in \u001b[0;36mgenerate_rag_response\u001b[0;34m(user_input)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_rag_response\u001b[39m(user_input):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Retrieve relevant document chunks\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     relevant_document_chunks \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241m.\u001b[39msimilarity_search(user_input, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      4\u001b[0m     context_list \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m relevant_document_chunks]\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Combine document chunks into a single context\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'retriever' is not defined"
          ]
        }
      ],
      "execution_count": 104,
      "metadata": {
        "gather": {
          "logged": 1737872737428
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Question 3: What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?\"   # Enter the question to be answered by the system here \n",
        "generate_rag_response(user_input)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1737178038767
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Question 4:  What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?\"   # Enter the question to be answered by the system here \n",
        "generate_rag_response(user_input)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1737178038790
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Question 5: What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?\"   # Enter the question to be answered by the system here \n",
        "generate_rag_response(user_input)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1737178038821
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Power Ahead!"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}